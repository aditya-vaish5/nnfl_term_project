{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnfl_termproject _lstm_working.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vaish5/nnfl_term_project/blob/master/nnfl_termproject__lstm_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uer1xgJvH6L6",
        "colab_type": "code",
        "outputId": "8a96b1b5-0fda-4482-c505-7e969b7ce950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-23 18:32:57--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13603614 (13M) [text/plain]\n",
            "Saving to: ‘train.en’\n",
            "\n",
            "train.en            100%[===================>]  12.97M  3.55MB/s    in 3.7s    \n",
            "\n",
            "2020-05-23 18:33:02 (3.55 MB/s) - ‘train.en’ saved [13603614/13603614]\n",
            "\n",
            "--2020-05-23 18:33:04--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18074646 (17M) [text/plain]\n",
            "Saving to: ‘train.vi’\n",
            "\n",
            "train.vi            100%[===================>]  17.24M  4.86MB/s    in 3.5s    \n",
            "\n",
            "2020-05-23 18:33:08 (4.86 MB/s) - ‘train.vi’ saved [18074646/18074646]\n",
            "\n",
            "--2020-05-23 18:33:10--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132264 (129K) [text/plain]\n",
            "Saving to: ‘tst2013.en’\n",
            "\n",
            "tst2013.en          100%[===================>] 129.16K   179KB/s    in 0.7s    \n",
            "\n",
            "2020-05-23 18:33:12 (179 KB/s) - ‘tst2013.en’ saved [132264/132264]\n",
            "\n",
            "--2020-05-23 18:33:14--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 183855 (180K) [text/plain]\n",
            "Saving to: ‘tst2013.vi’\n",
            "\n",
            "tst2013.vi          100%[===================>] 179.55K   214KB/s    in 0.8s    \n",
            "\n",
            "2020-05-23 18:33:16 (214 KB/s) - ‘tst2013.vi’ saved [183855/183855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advDQCZZIi60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLEfKM5Q6hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_to_read = 140000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlaQsvAUO9Jm",
        "colab_type": "code",
        "outputId": "faca6088-a17f-433f-b3f7-f5679904d4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "source": [
        "source_sent = []\n",
        "target_sent = []\n",
        "\n",
        "test_source_sent = []\n",
        "test_target_sent = []\n",
        "\n",
        "\n",
        "with open('train.en', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        # discarding first 20 translations as there was some\n",
        "        # english to english translations found in the first few. which are wrong\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        source_sent.append(line)\n",
        "        if len(source_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "with open('train.vi', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        \n",
        "        target_sent.append(line)\n",
        "        if len(target_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
        "\n",
        "print('Sample translations (%d)'%len(source_sent))\n",
        "for i in range(0,sentences_to_read,10000):\n",
        "    print('(',i,') EN: ', source_sent[i])\n",
        "    print('(',i,') VI: ', target_sent[i])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample translations (133267)\n",
            "( 0 ) EN:  In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .\n",
            "\n",
            "( 0 ) VI:  Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học .\n",
            "\n",
            "( 10000 ) EN:  This is an area in the prefrontal cortex , a region where we can use cognition to try to overcome aversive emotional states .\n",
            "\n",
            "( 10000 ) VI:  Đây là một khu vực trong vỏ não trước trán , vùng mà chúng sử dụng tri thức cho việc thử vượt qua trạng thái cảm xúc ác cảm .\n",
            "\n",
            "( 20000 ) EN:  And there are flowers that are self-infertile . That means they can &apos;t -- the pollen in their bloom can &apos;t fertilize themselves .\n",
            "\n",
            "( 20000 ) VI:  có những loài hoa không thể tự thụ phấn . Nghĩa là chúng không thể -- phấn hoa của nó không thể tụ thụ phấn được\n",
            "\n",
            "( 30000 ) EN:  And a lot of this comes together in a philosophy of change that I find really is powerful .\n",
            "\n",
            "( 30000 ) VI:  Và nhiều như vậy hợp lại thành một triết lý của sự thay đổi mà tôi thấy là thực sự rất mạnh .\n",
            "\n",
            "( 40000 ) EN:  Dean Ornish : At first for a long time , I wrote messages in notebooks .\n",
            "\n",
            "( 40000 ) VI:  Dean Ornish : &quot; Trong một khoảng thời gian dài ban đầu , tôi đã viết các tin nhắn trên các cuốn ghi chú .\n",
            "\n",
            "( 50000 ) EN:  World &apos;s first bamboo bike with folding handlebars .\n",
            "\n",
            "( 50000 ) VI:  Chiếc xe đạp bằng tre đầu tiên trên thế giới với ghi đông gập .\n",
            "\n",
            "( 60000 ) EN:  We need to invest more resources into research and treatment of mental illness .\n",
            "\n",
            "( 60000 ) VI:  Chúng ta cần đầu tư nhiều nguồn lực hơn cho công cuộc nghiên cứu và chữa trị về bệnh thần kinh .\n",
            "\n",
            "( 70000 ) EN:  If we are providing knowledge and experience , we need to structure that .\n",
            "\n",
            "( 70000 ) VI:  Nếu chúng ta cung cấp kiến thức và kinh nghiệm , chúng ta cần cơ cấu nó .\n",
            "\n",
            "( 80000 ) EN:  But I say it has to be under the conditions I &apos;ve always worked : no credit , no logos , no sponsoring .\n",
            "\n",
            "( 80000 ) VI:  Nhưng tôi nói nó phải theo các điều kiện tôi luôn luôn làm không có tín dụng , không có biểu tượng , không có tài trợ .\n",
            "\n",
            "( 90000 ) EN:  What would it look like ?\n",
            "\n",
            "( 90000 ) VI:  Nó sẽ trông như thế nào ?\n",
            "\n",
            "( 100000 ) EN:  And the 70 year-old ones , actually they &apos;re better at scouting out the good nesting places , and they also have more progeny every year .\n",
            "\n",
            "( 100000 ) VI:  Và những con 70 tuổi , thực sự giỏi hơn trong việc tìm kiếm một nơi để dựng tổ , và chúng cũng có nhiều con hơn hàng năm\n",
            "\n",
            "( 110000 ) EN:  The next time you dine on sushi -- or sashimi , or swordfish steak , or shrimp cocktail , whatever wildlife you happen to enjoy from the ocean -- think of the real cost .\n",
            "\n",
            "( 110000 ) VI:  Khi bạn thưởng thức sushi , hay sashimi , hay thịt cá kiếm nướng , hay cốc-tai tôm , bất kể thứ gì hoang dã từ đại dương mà bạn thưởng thức , hãy nghĩ về cái giá thực sự phải trả .\n",
            "\n",
            "( 120000 ) EN:  When I laid out my plan , I realized that I faced three main challenges : first , creating a sensor ; second , designing a circuit ; and third , coding a smartphone app .\n",
            "\n",
            "( 120000 ) VI:  Khi lập kế hoạch , tôi nhận ra mình đối mặt với 3 thách thức : thứ nhất , tạo ra một cảm biến ; thứ hai , thiết kế bảng mạch ; thứ ba , lập trình ứng dụng .\n",
            "\n",
            "( 130000 ) EN:  Why would you do something that dangerous ?\n",
            "\n",
            "( 130000 ) VI:  Tại sao bạn lại sẵn sàng làm một việc nguy hiểm như thế ?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlKPSSfRsEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.en') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZTwUWuIgLHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0,len(word_counts),10000):\n",
        "# print(word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs5Q5lQZbv5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e6v96s4b30B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_eng = OrderedDict(sorted(word_counts.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Wqju8hcSDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_eng=list(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKpJjMkfbDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnsHtGAcX36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_engg=sorted_train_eng[0:100000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ug4rNDac-7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_HO75i3cYSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(sorted_train_engg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlz5IzzldMgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.vi') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts_vi = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehg5nQPYdwhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_vi = OrderedDict(sorted(word_counts_vi.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrNkGcOietZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_vii=list(sorted_train_vi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4hmeRUBevmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_vii)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUoCchhiazp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1HkRGqhivpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.vi') as f:\n",
        "#     passage4 = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bgXuFYli7Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# passage4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGiFmExiI5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqNFoSdi8MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "\n",
        "# words_vi = re.findall(r'\\S+', passage4)\n",
        "# words_vi[-3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AMvKjnQjJQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ATG4EKjMPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLbwCAG1nB2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.50K.en') as f:\n",
        "#     passage3 = f.read()\n",
        "# words_en = re.findall(r'\\S+', passage3)\n",
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sua1PaHGabby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLpl2TsqnSH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !apt install gzip\n",
        "# # import gzip\n",
        "# # with gzip.open('/content/glove.6B.txt.gz') as f:\n",
        "# #   glove_vec = f.read()\n",
        "# !unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPMhgJkrhdvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzeFp9C7oiR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f = open('glove.6B.50d.txt', encoding= 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7goKXdeppd5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dic = {}\n",
        "# for line in f:\n",
        "#   v = line.split()\n",
        "#   word = v[0]\n",
        "#   vec = np.asarray(v[1:],dtype = 'float32')\n",
        "#   dic[word] = vec\n",
        "# f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjE1_f4npjRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(dic))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lNJeFkqlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove_dic =  OrderedDict(dic.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLAYvUjrjIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0, len(glove_dic) ,10000):\n",
        "#   print(glove_dic[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbt9pD6hr2IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAR8kXzRsMjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = itertools.islice(dic.items(), 0, len(dic),40000)\n",
        "\n",
        "# for key, value in x:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmru76M6nSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYX8cLWV7cPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRMBYLJ7GfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_eng_word(dic,word):\n",
        "#   try:\n",
        "#     x = dic[word]\n",
        "#     return x\n",
        "#   except KeyError:\n",
        "#     return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqLBLDM9T8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# eng_dict = {};\n",
        "# for w in sorted:\n",
        "#   eng_dict[w] = return_embedding_for_eng_word(dic,w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P63YsX9O9niK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eng_vects = itertools.islice(eng_dict.items(), 0, len(eng_dict),10000)\n",
        "\n",
        "# for key, value in eng_vects:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhG4fdR92Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(eng_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esjrjhm9_YXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_vietnamese_word():\n",
        "#   return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kATDp4v__t_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(words4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCHgN2Hi_x_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# viet_dict = {}\n",
        "# for w in words4:\n",
        "#   viet_dict[w] = return_embedding_for_vietnamese_word()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZDxdLL5klY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uH_VuWD5lvI",
        "colab_type": "code",
        "outputId": "6f8796cb-2666-4403-d0dc-c4f6e47e4704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDp726q5pWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tAZFIx5sAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMVraBNFfmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH \n",
        "        # and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br-e3-7E6EoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    pairs = [];\n",
        "    for i in range(0,len(target_sent)):\n",
        "      pairs.append([normalizeString(source_sent[i]) ,normalizeString(target_sent[i])])\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rJpzUK52MeJ",
        "colab_type": "code",
        "outputId": "3eb0750c-c292-4e0f-eff9-01fd193fec4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'vi')\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 133267 sentence pairs\n",
            "Trimmed to 66499 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 23610\n",
            "vi 7837\n",
            "['he doesn apos t have that same self worth .', 'gia tri cua anh khong giong truoc nua']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLyqU3WF700M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.input_size = input_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, bidirectional = True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell_state):\n",
        "        # print(\"forward running\")\n",
        "        # print(self.embedding(input).size())\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        # print(output.size())\n",
        "        # output, (hidden, cell_state) = self.lstm(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "        # print(output.size())\n",
        "        return output, hidden, cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "      return torch.zeros(2, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9UdlQE759q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIS CLASS ISN'T USED IN EVALUATION\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PotAA8uQ7_aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell_state, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        # print(attn_weights.unsqueeze(0).size(), encoder_outputs.unsqueeze(0).size())\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "        # print(embedded[0].size(),attn_applied[0].size())\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, cell_state, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVvbet88DNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZThP3EA8HRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder.initcellstate()\n",
        "    # print(\"setting optimizers to zero grad\")\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    # print(\"INPUT SIZE: \", input_tensor.size())\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      # print(\"starting encoder for \" , ei)\n",
        "      encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "          input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "      # print(encoder_output)\n",
        "      encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    for di in range(target_length):\n",
        "      # print(\"decoder for di : \", di)\n",
        "      decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "          decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "          break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2Gamqd8JiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdSWSxdv8NF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # print(\"train Iter optimizers set\")\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    # print(\"training pairs for this iteration have been assigned\")\n",
        "    # print(\"training pairs size\")\n",
        "    # print(len(training_pairs))\n",
        "    # print(len(training_pairs[0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(training_pairs[0][0])\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        # print(iter , \" : printing iter-1 th training pair\")\n",
        "        # print(training_pair)\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        # print(iter , \" : started training with above tensors\")\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        # print(iter,\" : current iter ended\");\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDY5Z2G8g5L",
        "colab_type": "code",
        "outputId": "bff07883-04a1-4c4b-b273-c43c3443bfc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "source": [
        "hidden_size = 100\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "print(\"Encoder initialization done\")\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "print(\"Decoder initialization done\")\n",
        "\n",
        "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "trainIters(encoder1, attn_decoder1, 50, print_every=1)"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder initialization done\n",
            "Decoder initialization done\n",
            "0m 0s (- 0m 2s) (1 2%) 8.9744\n",
            "0m 0s (- 0m 1s) (2 4%) 8.9686\n",
            "0m 0s (- 0m 2s) (3 6%) 8.9605\n",
            "0m 0s (- 0m 1s) (4 8%) 8.9636\n",
            "0m 0s (- 0m 1s) (5 10%) 8.8947\n",
            "0m 0s (- 0m 1s) (6 12%) 4.4677\n",
            "0m 0s (- 0m 1s) (7 14%) 8.9344\n",
            "0m 0s (- 0m 1s) (8 16%) 2.1075\n",
            "0m 0s (- 0m 1s) (9 18%) 5.4047\n",
            "0m 0s (- 0m 1s) (10 20%) 6.7142\n",
            "0m 0s (- 0m 1s) (11 22%) 1.4819\n",
            "0m 0s (- 0m 1s) (12 24%) 5.9912\n",
            "0m 0s (- 0m 1s) (13 26%) 3.5794\n",
            "0m 0s (- 0m 1s) (14 28%) 5.2372\n",
            "0m 0s (- 0m 0s) (15 30%) 2.4890\n",
            "0m 0s (- 0m 0s) (16 32%) 4.1821\n",
            "0m 0s (- 0m 0s) (17 34%) 3.1481\n",
            "0m 0s (- 0m 0s) (18 36%) 8.9644\n",
            "0m 0s (- 0m 0s) (19 38%) 5.2179\n",
            "0m 0s (- 0m 0s) (20 40%) 3.1679\n",
            "0m 0s (- 0m 0s) (21 42%) 3.5965\n",
            "0m 0s (- 0m 0s) (22 44%) 4.4917\n",
            "0m 0s (- 0m 0s) (23 46%) 4.0673\n",
            "0m 0s (- 0m 0s) (24 48%) 1.2634\n",
            "0m 0s (- 0m 0s) (25 50%) 8.9373\n",
            "0m 0s (- 0m 0s) (26 52%) 7.4221\n",
            "0m 0s (- 0m 0s) (27 54%) 2.2499\n",
            "0m 0s (- 0m 0s) (28 56%) 3.5681\n",
            "0m 0s (- 0m 0s) (29 57%) 4.2100\n",
            "0m 0s (- 0m 0s) (30 60%) 8.8317\n",
            "0m 0s (- 0m 0s) (31 62%) 7.1250\n",
            "0m 0s (- 0m 0s) (32 64%) 1.7967\n",
            "0m 0s (- 0m 0s) (33 66%) 6.6872\n",
            "0m 0s (- 0m 0s) (34 68%) 2.4058\n",
            "0m 0s (- 0m 0s) (35 70%) 6.7175\n",
            "0m 0s (- 0m 0s) (36 72%) 4.4859\n",
            "0m 0s (- 0m 0s) (37 74%) 4.8264\n",
            "0m 1s (- 0m 0s) (38 76%) 8.8323\n",
            "0m 1s (- 0m 0s) (39 78%) 2.4447\n",
            "0m 1s (- 0m 0s) (40 80%) 2.2205\n",
            "0m 1s (- 0m 0s) (41 82%) 2.5625\n",
            "0m 1s (- 0m 0s) (42 84%) 1.3944\n",
            "0m 1s (- 0m 0s) (43 86%) 2.3669\n",
            "0m 1s (- 0m 0s) (44 88%) 3.4047\n",
            "0m 1s (- 0m 0s) (45 90%) 3.9467\n",
            "0m 1s (- 0m 0s) (46 92%) 2.3836\n",
            "0m 1s (- 0m 0s) (47 94%) 3.9497\n",
            "0m 1s (- 0m 0s) (48 96%) 3.9455\n",
            "0m 1s (- 0m 0s) (49 98%) 4.1484\n",
            "0m 1s (- 0m 0s) (50 100%) 2.6245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm8ns1zoJB-W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCEHLIb8Qnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS9We9ZU8bre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder.initcellstate()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden,encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden,encoder_cell)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = encoder_cell\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden,decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden,decoder_cell, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1dYNPb8eHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vca5iI5L0BRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ddbd88bd-7b70-4814-8719-3415e493552d"
      },
      "source": [
        "print(input_lang.n_words)"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DXfF12H8rNL",
        "colab_type": "code",
        "outputId": "568089de-a861-48f5-d254-bfa13a5184bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">  quot sputnik quot was downtown the negative . it wasn apos t touched .\n",
            "=  quot sputnik quot o khu buon trung tam ban am ban . no hay con nguyen ven .\n",
            "< toi toi toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> and you can pick a style . so this one was tagged quot abstract . quot \n",
            "= va ban co the chon kieu . cai nay uoc gan la quot truu tuong quot \n",
            "< toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> take for example this beautiful blue nacre shell .\n",
            "= lay vo xa cu mau xanh xinh ep nay lam vi du .\n",
            "< toi toi toi toi toi <EOS>\n",
            "\n",
            "> ok ?\n",
            "=  uoc chu ?\n",
            "< toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> i apos m worried that we are running into problems because of online crime .\n",
            "= toi lo lang vi chung ta am au vao van e boi vi toi pham truc tuyen\n",
            "< toi toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> but what about oil ? where is it in the energy system ?\n",
            "= nhung con ve dau mo ? au la vi tri cua no trong he thong nang luong ?\n",
            "< toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> but no this was far more attractive .\n",
            "= the ma khong no con hap dan hon the nua .\n",
            "< toi toi toi toi toi toi toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> and this logo !\n",
            "= va logo nay !\n",
            "< chung toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> the trick is to join them up to use food as a way of seeing .\n",
            "= van e mau chot la ket hop chung lai e su dung thuc pham nhu mot cach nhin .\n",
            "< toi toi toi toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> it apos s never happened before .\n",
            "=  ieu o chua bao gio xay ra .\n",
            "< toi toi toi toi toi <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WOs79j0BY_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icCvahalHOMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWda4e48FLT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "# import matplotlib.ticker as ticker\n",
        "# import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKVX8GNBzeR",
        "colab_type": "code",
        "outputId": "c5f277ce-d393-4137-edb8-7f4927bd15e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"so the sweet spot is between and .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe6dc9bf1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP6AsgTbBrA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_VdBg6EzfT",
        "colab_type": "code",
        "outputId": "9c8d35f6-a528-4e27-868b-9baca2174b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention( \"so the sweet spot is between and .\")\n"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = so the sweet spot is between and .\n",
            "output = toi toi toi toi toi toi toi toi toi toi toi toi toi toi <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpaNLG_FG2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_GdRlFcc8",
        "colab_type": "code",
        "outputId": "af6ed3fa-9290-4f4b-f5cf-b03c836179f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "print(attentions.numpy())"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.04520178 0.03027663 0.03072606 0.03151767 0.05519724 0.06406497\n",
            "  0.09046509 0.0867083  0.06732447 0.0491231  0.042453   0.04482097\n",
            "  0.06692479 0.03181482 0.04447208 0.03368972 0.05087583 0.05872159\n",
            "  0.03837779 0.03724406]\n",
            " [0.02749943 0.04155677 0.03652975 0.09313902 0.05002115 0.03735595\n",
            "  0.02579931 0.02269348 0.02917498 0.09929609 0.04322501 0.07166545\n",
            "  0.01400756 0.10711893 0.05616025 0.08737234 0.04837253 0.02434758\n",
            "  0.04954956 0.03511481]\n",
            " [0.02870559 0.04243385 0.03291271 0.09821911 0.05696926 0.03483666\n",
            "  0.02400109 0.02029398 0.03535055 0.09476084 0.05781328 0.06023954\n",
            "  0.01629281 0.10712983 0.06524257 0.08381549 0.03669002 0.02340049\n",
            "  0.04733367 0.03355869]\n",
            " [0.03196902 0.03883119 0.03048442 0.08669454 0.04479698 0.03070861\n",
            "  0.02560329 0.02108438 0.02728894 0.11444042 0.04865906 0.08217566\n",
            "  0.01961077 0.11735271 0.05569561 0.06952729 0.04146516 0.02870698\n",
            "  0.0451126  0.03979233]\n",
            " [0.0290892  0.03393772 0.03043205 0.08859221 0.03357383 0.0439871\n",
            "  0.02460104 0.02112499 0.03137692 0.12315678 0.03491548 0.07869173\n",
            "  0.02263218 0.10871685 0.07518119 0.06425798 0.04113305 0.02702214\n",
            "  0.04178962 0.04578795]\n",
            " [0.02853307 0.03530471 0.0408287  0.07805329 0.04969777 0.03738704\n",
            "  0.02362777 0.02217814 0.02720246 0.09754778 0.04537289 0.07256754\n",
            "  0.01802896 0.09610159 0.05996254 0.11125439 0.0381635  0.03070522\n",
            "  0.05486344 0.03261914]\n",
            " [0.0279055  0.03763019 0.0424723  0.08156711 0.06394508 0.03818005\n",
            "  0.02227143 0.02122645 0.03046024 0.09058707 0.04868535 0.07054278\n",
            "  0.01853128 0.10211583 0.06906873 0.08147059 0.04487142 0.02132392\n",
            "  0.03823122 0.04891341]\n",
            " [0.02476781 0.03999111 0.0405707  0.08183564 0.03794507 0.03829088\n",
            "  0.02650339 0.02139561 0.02625987 0.1172043  0.04219655 0.08807979\n",
            "  0.01889584 0.0896855  0.07732679 0.08445267 0.03971439 0.0222804\n",
            "  0.04232618 0.04027753]\n",
            " [0.02873967 0.0364267  0.03902221 0.08839744 0.0474562  0.03660523\n",
            "  0.02603396 0.01879391 0.03028946 0.09786246 0.04688765 0.07861114\n",
            "  0.02001129 0.1058542  0.0586082  0.08768833 0.03914475 0.0254889\n",
            "  0.04405561 0.04402266]\n",
            " [0.02866922 0.05060545 0.04168177 0.0764374  0.04477843 0.03127105\n",
            "  0.02885693 0.01985781 0.04500725 0.13512586 0.05853253 0.07379609\n",
            "  0.02051657 0.07349602 0.05741971 0.05934072 0.03476493 0.03610623\n",
            "  0.0422826  0.04145348]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA24gW3JFz35",
        "colab_type": "code",
        "outputId": "948ed3fe-c5b0-4cfd-ab53-d4a0acd01cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe6dbc918d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-6wIjIdpVNu",
        "colab_type": "text"
      },
      "source": [
        "1. BiLSTM\n",
        "2. GloVE embedding\n",
        "3. presentation\n",
        "4. BLUE Score and how error is calculated here\n",
        "5. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YOZ1jJGndf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}