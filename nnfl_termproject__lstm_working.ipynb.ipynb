{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nnfl_termproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vaish5/nnfl_term_project/blob/master/nnfl_termproject__lstm_working.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uer1xgJvH6L6",
        "colab_type": "code",
        "outputId": "6418c05b-4964-4dd0-83dd-3020f8615324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 09:29:12--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13603614 (13M) [text/plain]\n",
            "Saving to: ‘train.en’\n",
            "\n",
            "train.en            100%[===================>]  12.97M  3.52MB/s    in 3.7s    \n",
            "\n",
            "2020-05-24 09:29:16 (3.52 MB/s) - ‘train.en’ saved [13603614/13603614]\n",
            "\n",
            "--2020-05-24 09:29:20--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18074646 (17M) [text/plain]\n",
            "Saving to: ‘train.vi’\n",
            "\n",
            "train.vi            100%[===================>]  17.24M  4.35MB/s    in 4.0s    \n",
            "\n",
            "2020-05-24 09:29:25 (4.35 MB/s) - ‘train.vi’ saved [18074646/18074646]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advDQCZZIi60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLEfKM5Q6hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_to_read = 140000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlaQsvAUO9Jm",
        "colab_type": "code",
        "outputId": "9910be07-7a94-4368-c460-a209f8d950a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "source": [
        "source_sent = []\n",
        "target_sent = []\n",
        "\n",
        "test_source_sent = []\n",
        "test_target_sent = []\n",
        "\n",
        "\n",
        "with open('train.en', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        # discarding first 20 translations as there was some\n",
        "        # english to english translations found in the first few. which are wrong\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        source_sent.append(line)\n",
        "        if len(source_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "with open('train.vi', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        \n",
        "        target_sent.append(line)\n",
        "        if len(target_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
        "\n",
        "print('Sample translations (%d)'%len(source_sent))\n",
        "for i in range(0,sentences_to_read,10000):\n",
        "    print('(',i,') EN: ', source_sent[i])\n",
        "    print('(',i,') VI: ', target_sent[i])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample translations (133267)\n",
            "( 0 ) EN:  In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .\n",
            "\n",
            "( 0 ) VI:  Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học .\n",
            "\n",
            "( 10000 ) EN:  This is an area in the prefrontal cortex , a region where we can use cognition to try to overcome aversive emotional states .\n",
            "\n",
            "( 10000 ) VI:  Đây là một khu vực trong vỏ não trước trán , vùng mà chúng sử dụng tri thức cho việc thử vượt qua trạng thái cảm xúc ác cảm .\n",
            "\n",
            "( 20000 ) EN:  And there are flowers that are self-infertile . That means they can &apos;t -- the pollen in their bloom can &apos;t fertilize themselves .\n",
            "\n",
            "( 20000 ) VI:  có những loài hoa không thể tự thụ phấn . Nghĩa là chúng không thể -- phấn hoa của nó không thể tụ thụ phấn được\n",
            "\n",
            "( 30000 ) EN:  And a lot of this comes together in a philosophy of change that I find really is powerful .\n",
            "\n",
            "( 30000 ) VI:  Và nhiều như vậy hợp lại thành một triết lý của sự thay đổi mà tôi thấy là thực sự rất mạnh .\n",
            "\n",
            "( 40000 ) EN:  Dean Ornish : At first for a long time , I wrote messages in notebooks .\n",
            "\n",
            "( 40000 ) VI:  Dean Ornish : &quot; Trong một khoảng thời gian dài ban đầu , tôi đã viết các tin nhắn trên các cuốn ghi chú .\n",
            "\n",
            "( 50000 ) EN:  World &apos;s first bamboo bike with folding handlebars .\n",
            "\n",
            "( 50000 ) VI:  Chiếc xe đạp bằng tre đầu tiên trên thế giới với ghi đông gập .\n",
            "\n",
            "( 60000 ) EN:  We need to invest more resources into research and treatment of mental illness .\n",
            "\n",
            "( 60000 ) VI:  Chúng ta cần đầu tư nhiều nguồn lực hơn cho công cuộc nghiên cứu và chữa trị về bệnh thần kinh .\n",
            "\n",
            "( 70000 ) EN:  If we are providing knowledge and experience , we need to structure that .\n",
            "\n",
            "( 70000 ) VI:  Nếu chúng ta cung cấp kiến thức và kinh nghiệm , chúng ta cần cơ cấu nó .\n",
            "\n",
            "( 80000 ) EN:  But I say it has to be under the conditions I &apos;ve always worked : no credit , no logos , no sponsoring .\n",
            "\n",
            "( 80000 ) VI:  Nhưng tôi nói nó phải theo các điều kiện tôi luôn luôn làm không có tín dụng , không có biểu tượng , không có tài trợ .\n",
            "\n",
            "( 90000 ) EN:  What would it look like ?\n",
            "\n",
            "( 90000 ) VI:  Nó sẽ trông như thế nào ?\n",
            "\n",
            "( 100000 ) EN:  And the 70 year-old ones , actually they &apos;re better at scouting out the good nesting places , and they also have more progeny every year .\n",
            "\n",
            "( 100000 ) VI:  Và những con 70 tuổi , thực sự giỏi hơn trong việc tìm kiếm một nơi để dựng tổ , và chúng cũng có nhiều con hơn hàng năm\n",
            "\n",
            "( 110000 ) EN:  The next time you dine on sushi -- or sashimi , or swordfish steak , or shrimp cocktail , whatever wildlife you happen to enjoy from the ocean -- think of the real cost .\n",
            "\n",
            "( 110000 ) VI:  Khi bạn thưởng thức sushi , hay sashimi , hay thịt cá kiếm nướng , hay cốc-tai tôm , bất kể thứ gì hoang dã từ đại dương mà bạn thưởng thức , hãy nghĩ về cái giá thực sự phải trả .\n",
            "\n",
            "( 120000 ) EN:  When I laid out my plan , I realized that I faced three main challenges : first , creating a sensor ; second , designing a circuit ; and third , coding a smartphone app .\n",
            "\n",
            "( 120000 ) VI:  Khi lập kế hoạch , tôi nhận ra mình đối mặt với 3 thách thức : thứ nhất , tạo ra một cảm biến ; thứ hai , thiết kế bảng mạch ; thứ ba , lập trình ứng dụng .\n",
            "\n",
            "( 130000 ) EN:  Why would you do something that dangerous ?\n",
            "\n",
            "( 130000 ) VI:  Tại sao bạn lại sẵn sàng làm một việc nguy hiểm như thế ?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlKPSSfRsEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.en') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZTwUWuIgLHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0,len(word_counts),10000):\n",
        "# print(word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs5Q5lQZbv5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e6v96s4b30B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_eng = OrderedDict(sorted(word_counts.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Wqju8hcSDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_eng=list(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKpJjMkfbDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnsHtGAcX36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_engg=sorted_train_eng[0:100000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ug4rNDac-7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_HO75i3cYSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(sorted_train_engg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlz5IzzldMgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.vi') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts_vi = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehg5nQPYdwhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_vi = OrderedDict(sorted(word_counts_vi.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrNkGcOietZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_vii=list(sorted_train_vi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4hmeRUBevmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_vii)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUoCchhiazp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1HkRGqhivpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.vi') as f:\n",
        "#     passage4 = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bgXuFYli7Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# passage4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGiFmExiI5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqNFoSdi8MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "\n",
        "# words_vi = re.findall(r'\\S+', passage4)\n",
        "# words_vi[-3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AMvKjnQjJQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ATG4EKjMPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLbwCAG1nB2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.50K.en') as f:\n",
        "#     passage3 = f.read()\n",
        "# words_en = re.findall(r'\\S+', passage3)\n",
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sua1PaHGabby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLpl2TsqnSH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !apt install gzip\n",
        "# # import gzip\n",
        "# # with gzip.open('/content/glove.6B.txt.gz') as f:\n",
        "# #   glove_vec = f.read()\n",
        "# !unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPMhgJkrhdvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzeFp9C7oiR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f = open('glove.6B.50d.txt', encoding= 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7goKXdeppd5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dic = {}\n",
        "# for line in f:\n",
        "#   v = line.split()\n",
        "#   word = v[0]\n",
        "#   vec = np.asarray(v[1:],dtype = 'float32')\n",
        "#   dic[word] = vec\n",
        "# f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjE1_f4npjRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(dic))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lNJeFkqlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove_dic =  OrderedDict(dic.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLAYvUjrjIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0, len(glove_dic) ,10000):\n",
        "#   print(glove_dic[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbt9pD6hr2IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAR8kXzRsMjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = itertools.islice(dic.items(), 0, len(dic),40000)\n",
        "\n",
        "# for key, value in x:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmru76M6nSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYX8cLWV7cPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRMBYLJ7GfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_eng_word(dic,word):\n",
        "#   try:\n",
        "#     x = dic[word]\n",
        "#     return x\n",
        "#   except KeyError:\n",
        "#     return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqLBLDM9T8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# eng_dict = {};\n",
        "# for w in sorted:\n",
        "#   eng_dict[w] = return_embedding_for_eng_word(dic,w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P63YsX9O9niK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eng_vects = itertools.islice(eng_dict.items(), 0, len(eng_dict),10000)\n",
        "\n",
        "# for key, value in eng_vects:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhG4fdR92Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(eng_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esjrjhm9_YXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_vietnamese_word():\n",
        "#   return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kATDp4v__t_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(words4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCHgN2Hi_x_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# viet_dict = {}\n",
        "# for w in words4:\n",
        "#   viet_dict[w] = return_embedding_for_vietnamese_word()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaUn80e2BZXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZDxdLL5klY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uH_VuWD5lvI",
        "colab_type": "code",
        "outputId": "3d9f60be-b0bd-4d61-b1cb-44215785bc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDp726q5pWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tAZFIx5sAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMVraBNFfmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH \n",
        "        # and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br-e3-7E6EoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    pairs = [];\n",
        "    for i in range(0,len(target_sent)):\n",
        "      pairs.append([normalizeString(source_sent[i]) ,normalizeString(target_sent[i])])\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rJpzUK52MeJ",
        "colab_type": "code",
        "outputId": "5e8bb96c-ca10-4f59-e3cd-a8bb2f65f39d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'vi')\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 133267 sentence pairs\n",
            "Trimmed to 66499 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 23610\n",
            "vi 7837\n",
            "['that one kind of rolls off your tongue .', 'chung lam cong luoi cua ban .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLyqU3WF700M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.input_size = input_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, bidirectional = True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell_state):\n",
        "        # print(\"forward running\")\n",
        "        # print(self.embedding(input).size())\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        # print(output.size())\n",
        "        # output, (hidden, cell_state) = self.lstm(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "        # print(output.size())\n",
        "        return output, hidden, cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "      return torch.zeros(2, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9UdlQE759q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIS CLASS ISN'T USED IN EVALUATION\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(hidden_size*2, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden,cell_state):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden,cell_state = self.lstm(output, (hidden,cell_state))\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden,cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PotAA8uQ7_aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell_state, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        # print(attn_weights.unsqueeze(0).size(), encoder_outputs.unsqueeze(0).size())\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "        # print(embedded[0].size(),attn_applied[0].size())\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, cell_state, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVvbet88DNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZThP3EA8HRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder.initcellstate()\n",
        "    # print(\"setting optimizers to zero grad\")\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    # print(\"INPUT SIZE: \", input_tensor.size())\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      # print(\"starting encoder for \" , ei)\n",
        "      encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "          input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "      # print(encoder_output)\n",
        "      encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    for di in range(target_length):\n",
        "      # print(\"decoder for di : \", di)\n",
        "      decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "          decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "          break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2Gamqd8JiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdSWSxdv8NF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # print(\"train Iter optimizers set\")\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    # print(\"training pairs for this iteration have been assigned\")\n",
        "    # print(\"training pairs size\")\n",
        "    # print(len(training_pairs))\n",
        "    # print(len(training_pairs[0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(training_pairs[0][0])\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        # print(iter , \" : printing iter-1 th training pair\")\n",
        "        # print(training_pair)\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        # print(iter , \" : started training with above tensors\")\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        # print(iter,\" : current iter ended\");\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDY5Z2G8g5L",
        "colab_type": "code",
        "outputId": "538531de-2b10-4d5d-9975-f0a566bd785a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "source": [
        "hidden_size = 100\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "print(\"Encoder initialization done\")\n",
        "# attn_decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "print(\"Decoder initialization done\")\n",
        "\n",
        "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "trainIters(encoder1, attn_decoder1, 50, print_every=1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder initialization done\n",
            "Decoder initialization done\n",
            "0m 0s (- 0m 3s) (1 2%) 8.9645\n",
            "0m 0s (- 0m 3s) (2 4%) 8.9891\n",
            "0m 0s (- 0m 3s) (3 6%) 8.9499\n",
            "0m 0s (- 0m 3s) (4 8%) 8.9456\n",
            "0m 0s (- 0m 3s) (5 10%) 8.9686\n",
            "0m 0s (- 0m 2s) (6 12%) 8.9143\n",
            "0m 0s (- 0m 2s) (7 14%) 8.9600\n",
            "0m 0s (- 0m 2s) (8 16%) 8.9121\n",
            "0m 0s (- 0m 2s) (9 18%) 3.1640\n",
            "0m 0s (- 0m 2s) (10 20%) 8.9256\n",
            "0m 0s (- 0m 2s) (11 22%) 3.1509\n",
            "0m 0s (- 0m 2s) (12 24%) 6.8689\n",
            "0m 0s (- 0m 2s) (13 26%) 1.3358\n",
            "0m 0s (- 0m 2s) (14 28%) 2.3442\n",
            "0m 0s (- 0m 2s) (15 30%) 8.8877\n",
            "0m 0s (- 0m 1s) (16 32%) 7.6134\n",
            "0m 0s (- 0m 1s) (17 34%) 8.9110\n",
            "0m 1s (- 0m 1s) (18 36%) 0.6504\n",
            "0m 1s (- 0m 1s) (19 38%) 8.8814\n",
            "0m 1s (- 0m 1s) (20 40%) 0.5302\n",
            "0m 1s (- 0m 1s) (21 42%) 1.1251\n",
            "0m 1s (- 0m 1s) (22 44%) 0.7420\n",
            "0m 1s (- 0m 1s) (23 46%) 1.1061\n",
            "0m 1s (- 0m 1s) (24 48%) 0.5232\n",
            "0m 1s (- 0m 1s) (25 50%) 8.8627\n",
            "0m 1s (- 0m 1s) (26 52%) 1.0083\n",
            "0m 1s (- 0m 1s) (27 54%) 2.2463\n",
            "0m 1s (- 0m 1s) (28 56%) 0.5651\n",
            "0m 1s (- 0m 0s) (29 57%) 0.5262\n",
            "0m 1s (- 0m 0s) (30 60%) 1.1263\n",
            "0m 1s (- 0m 0s) (31 62%) 2.2423\n",
            "0m 1s (- 0m 0s) (32 64%) 1.2794\n",
            "0m 1s (- 0m 0s) (33 66%) 1.0072\n",
            "0m 1s (- 0m 0s) (34 68%) 1.1251\n",
            "0m 1s (- 0m 0s) (35 70%) 0.6328\n",
            "0m 1s (- 0m 0s) (36 72%) 0.6851\n",
            "0m 1s (- 0m 0s) (37 74%) 1.1113\n",
            "0m 1s (- 0m 0s) (38 76%) 8.8873\n",
            "0m 1s (- 0m 0s) (39 78%) 0.6791\n",
            "0m 1s (- 0m 0s) (40 80%) 8.8627\n",
            "0m 1s (- 0m 0s) (41 82%) 1.1300\n",
            "0m 1s (- 0m 0s) (42 84%) 8.8132\n",
            "0m 1s (- 0m 0s) (43 86%) 8.8326\n",
            "0m 1s (- 0m 0s) (44 88%) 0.9751\n",
            "0m 1s (- 0m 0s) (45 90%) 8.8052\n",
            "0m 1s (- 0m 0s) (46 92%) 8.6743\n",
            "0m 1s (- 0m 0s) (47 94%) 1.1294\n",
            "0m 1s (- 0m 0s) (48 96%) 8.7878\n",
            "0m 2s (- 0m 0s) (49 98%) 8.7479\n",
            "0m 2s (- 0m 0s) (50 100%) 8.6405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm8ns1zoJB-W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCEHLIb8Qnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS9We9ZU8bre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder.initcellstate()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden,encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden,encoder_cell)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = encoder_cell\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden,decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden,decoder_cell, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1dYNPb8eHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vca5iI5L0BRw",
        "colab_type": "code",
        "outputId": "9a2a1243-f1f8-49c3-af64-6c015ad79055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(input_lang.n_words)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DXfF12H8rNL",
        "colab_type": "code",
        "outputId": "7d882735-9f28-4b85-b0f0-d4276f5bbb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> every time somebody looks at you you think people are staring at you .\n",
            "= moi khi ai o nhin ban ban nghi rang ho ang nhin cham cham vao minh .\n",
            "< <EOS>\n",
            "\n",
            "> so the next day you know after i thought quot well he might be right . quot \n",
            "= sang ngay hom sau toi chot nghi quot cha ong ta co the ung o chu quot \n",
            "< . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "> so teachers and students all around the world are already using this .\n",
            "= giao vien va hoc sinh tren the gioi hien ang su dung chuong trinh nay .\n",
            "< <EOS>\n",
            "\n",
            "> they really influence people .\n",
            "= chung that su anh huong toi con nguoi .\n",
            "< . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "> the street is the lab .\n",
            "= phong thi nghiem cua ho o le uong .\n",
            "< <EOS>\n",
            "\n",
            "> but this is only one half of the story .\n",
            "= nhung o chi la mot phan cua van e .\n",
            "< . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "> that apos s the wonderful richness of life .\n",
            "=  o la su giau co phi thuong cua cuoc song .\n",
            "< <EOS>\n",
            "\n",
            "> it apos s all a little bit frightening and emotional .\n",
            "= cung hoi run so chut va ay cam xuc .\n",
            "< <EOS>\n",
            "\n",
            "> the mystery persisted for about years .\n",
            "= bi an ton tai suot nam .\n",
            "< . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "> you have about genes .\n",
            "= ban co khoang . gen\n",
            "< <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WOs79j0BY_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icCvahalHOMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWda4e48FLT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "# import matplotlib.ticker as ticker\n",
        "# import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKVX8GNBzeR",
        "colab_type": "code",
        "outputId": "b4a5c536-3529-4118-cbf7-4a10b1f28590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"so the sweet spot is between and .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f55310bd080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARGElEQVR4nO3dW4yc91nH8d8zp53xru3s+rB1YjcNjhMSqOoEN5WgoikNUVoJpbkAEQkUpErORSPEZe5aIS4qQdUboMhVc7hpEAWlzUVpGwxS6AGBI6zinN0kJnY2Xh/3PDM7M38uPJZM7Fk/f+/OjL3P9yNFuzt+8vr/vu/sb98ZP++zllISgLgKw14AgOEiBIDgCAEgOEIACI4QAIIjBIDghhoCZvaQmb1hZkfN7MlhrqUfzOxdM/sfMztsZoeGvZ7VMrOnzGzazI5c8tiEmb1oZm91P44Pc42r0WP/vmpmJ7rn8LCZfWGYa+yHoYWAmRUl/Y2kz0u6W9KjZnb3sNbTR59NKe1NKe0b9kLWwDOSHvrQY09KOphS2iPpYPfrG9Uzunz/JOkb3XO4N6X0gwGvqe+GeSVwn6SjKaW3U0pNSX8v6eEhrgdXkVJ6SdLZDz38sKRnu58/K+mLA13UGuqxf+veMEPgFknvXfL18e5j60mS9GMze9nM9g97MX0ymVKa6n7+gaTJYS6mT54ws190Xy7csC93euGNwf76dErpXl14yfNlM/vtYS+on9KFHvT11of+TUm7Je2VNCXp68NdztobZgickLTrkq93dh9bN1JKJ7ofpyU9rwsvgdabk2a2Q5K6H6eHvJ41lVI6mVJqp5Q6kr6ldXgOhxkC/yVpj5ndZmYVSX8o6YUhrmdNmdmomW28+LmkByUdWfn/uiG9IOmx7uePSfr+ENey5i4GXNcjWofnsDSsvzil1DKzJyT9SFJR0lMppVeGtZ4+mJT0vJlJF47zd1JKPxzuklbHzJ6TdL+krWZ2XNJXJH1N0j+Y2ZckHZP0B8Nb4er02L/7zWyvLrzMeVfS40NbYJ8YtxIDsfHGIBAcIQAERwgAwRECQHCEABDcdREC67ildl3vm8T+rQfXRQhIWs8Hej3vm8T+3fCulxAAMCQDbRYqbhxNpW2X34TVnl1QcdPo/3usfM7c27XMfSg02u7a5U3+psrOxsu3255ZVHHzhsseL5/y52/KjWrzH7vlTRnHrnP5dtvz8yqOjV32+MgZ/zHujBT9a5BUrPu33drg33ax3rnsseXlBZXLo5cX+w+xOuW8E9ie8O9f+aRvIfX6eTWXF65YPNC24dK2ce348y+7am/5Xtm93SudvJVsODbrrn3/d7a4a5uf8W93+7dr7tpOJeMZJ6lV9T/ppj7nf8JZ3b/dO56ed9fO7748RFay8c0Zd+2Ze/x3/o6/5l9zp+b/1lnaVnHXStLcH/mfR5N/OeKq+8/Df9vzz1b1cmC9jwcDIrjmEAg0HgxY11ZzJcB4MGAdWE0IRBgPBqx7ff8nQjPbb2aHzOxQe3ah338dgEyrCQHXeLCU0oGU0r6U0r4P/zMggOFbTQis6/FgQBTX3CcQYDwYEMKqmoW6v43F/RtZrGkqv+drbigtLLvX8d4D/sYiSSrs8q1Bkmr/4d9u59WN7tpjv+dv0tn93ZZ/EZLO3lV1144d9V8M7vjporv2zT/xH4vd/9hw10pSa5N//7b+7KR/w+f8TUinfv8Od+34G03/GiRV/vryDtOekvO5sUJjKPcOAMERAkBwhAAQHCEABEcIAMERAkBwhAAQHCEABEcIAMERAkBwA50xmIrS8k3OeYAZwzI3/TJvHQ89cNhd+09Hf8tdu2EqY8DnRn/+zt7qb3O+sA7/8NBzd/m3uzzmf7rc9Lr/WBTreW3RhcWMNtxZ/9zAdPM2d+3E6/5W58Z4Xlt7a8R/7GpnfLWp2LuOKwEgOEIACI4QAIIjBIDgCAEgOEIACI4QAIIjBIDgCAEgOEIACI4QAIIb6L0D6kjW8PU6l2f8/eHtkbze7O++dq+7NtX8ffilJf8aOpv8/fK1M3lZXZn1j2ufud0/vnt5rOiund919ZqLtrzav6dhseTfdmOb/zdkFRf956+xKe/ej2LT/5xrbvKdE+4dANATIQAERwgAwRECQHCEABAcIQAERwgAwRECQHCEABAcIQAEN9C2YetIlVlf7rRr/qW1/Z2vkqQ/23vQXftX5z/vrq1P+NdcPVZx17YrbXetJJ27I6MVeLNzBLykkXP+VtnynL9Vtrjgb3OWpMKCf9x3qtfdtSPHZ9y1jZ2b3bXlBf8xlqTqWf9xXqkd+FLW7t2KzJUAEBwhAARHCADBEQJAcIQAEBwhAARHCADBEQJAcIQAEBwhAAQ30LbhQlMaPe6bpLq80T/ZNtdz//tJf7GvK1OS1K75axu7/e2seiVvmnK74l905bz/50C76q/NmbycChkHWZIKGT+7Cv7nUar6j3Mpo9V5aY+/RVySyov+/SvP+1qMrUPbMIAeCAEguFW9HDCzdyXNSWpLaqWU9q3FogAMzlq8J/DZlNLpNdgOgCHg5QAQ3GpDIEn6sZm9bGb7r1RgZvvN7JCZHWrVF1b51wFYa6t9OfDplNIJM9su6UUzez2l9NKlBSmlA5IOSNKGbbv8v2kRwECs6kogpXSi+3Fa0vOS7luLRQEYnGsOATMbNbONFz+X9KCkI2u1MACDsZqXA5OSnjezi9v5Tkrph2uyKgADc80hkFJ6W9Incv6fTlla/IivRbQy779IGTmf91bDX+z5nrv28Zcf96/jbMYijvonAreqedNqs1qdMyY1l5b8U4+t7W/BbY3ltdWmov+5UXjTP0HYJrf4t1v3TwQem8qbFt2qZVygd3zfwiu1ZvNPhEBwhAAQHCEABEcIAMERAkBwhAAQHCEABEcIAMERAkBwhAAQ3ECnDasgtWu+Ft9Cy98KXKznTav9l7lfc9eOHfNvt5MxFNjZ7dndbt7+tTb4a9uj/pbkVtU/uXd2j79VduuRvLbvQtPfsmsV/0kpnJ9z1y7dvcNdW5vKGL0saf5jo1n1q8WVABAcIQAERwgAwRECQHCEABAcIQAERwgAwRECQHCEABAcIQAERwgAwQ303gFrS6V5Xx98ymiXT5lR9qPjd7lrF2/2L6S06F9DY7u//7363/7tSlIyf49/Vm3J3+NfPeXf7vJY3r0DxSX/sStU/OPMm7u3u2st496WuV/JuxfAMibMW2f1v9mPKwEgOEIACI4QAIIjBIDgCAEgOEIACI4QAIIjBIDgCAEgOEIACG6gbcPJ/C2+G6ab7u3O76xlrePerVPu2p/Utrhrq6f9LcaFhj9/Z3flZXVp0d9K2rzJX9uuZOzfsrtUI6cb/mJJxbML7tr2uXPu2sLSTndtZ8zfjjxyzt/mLEmdsv98Nzf7voVTsfe540oACI4QAIIjBIDgCAEgOEIACI4QAIIjBIDgCAEgOEIACI4QAIIbaNtwoSWNOLs4bdk/cnX8jYweVUlPf/Tf3bW3bb3TXVtf8reSVqf9+ZszfVaSCm1/bXk2Y5py3b8Q6/inDedqT/in95Z2+VuBdXrOXbq8yd9OXqpnnBBJ8xP+b8vRKV97fWGF6chcCQDBXTUEzOwpM5s2syOXPDZhZi+a2Vvdj+P9XSaAfvFcCTwj6aEPPfakpIMppT2SDna/BnADumoIpJReknT2Qw8/LOnZ7ufPSvriGq8LwIBc63sCkymlizflfyBpco3WA2DAVv3GYEopSer51qOZ7TezQ2Z2qLXkHwYBYDCuNQROmtkOSep+nO5VmFI6kFLal1LaV6rl/WJGAP13rSHwgqTHup8/Jun7a7McAIPm+SfC5yT9XNKdZnbczL4k6WuSftfM3pL0QPdrADegq7YmpZQe7fFHn1vjtQAYgoG2DXdKUmPCWVvxt52e/ng5ax1/+v4n3bW25F+HZQyVXR7zT/mtzPhbeyWpdsbfpnrqU/7tln/m38HKjP+pVWjl9UUX3nnfXduem3fXpnsyWsS3+p9zlZm8tuGRjPqFHb5W9XaZacMAeiAEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAG2jYskzrObstOxZ9P7VreMk43xty1pTn/Oqqn/a3As3v8tRtP5LWdtmoZk4yX/evIcf5X/dvd/vO8adGNT3zMXVv95Sn/hqdn3aWd2ze4ayuzefu3cEvVXXvTqzOuutJS7+cQVwJAcIQAEBwhAARHCADBEQJAcIQAEBwhAARHCADBEQJAcIQAEBwhAAQ30HsHUlFa3uwbL93OuHeg9kFe//uxuXF3bbHhH/dd3+Jfg2W0k8/v8I89l6SlbRkjygv++xLaI/51jL/iX0NrPO/mj+qbJ9217akP3LV29+3u2g3T/vHr1s4bqd7Y7D92jUnfr/brvN37+4krASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIbqBtw4VlqTrty51CK6OdtZbRJiupWvK3fLYr/pbkibf8taU/nnbXlv9twl0rSaMf+Nt7p/f5fw50iv721zO/4T9/E6/ltX13xv0j4wt1f4u4lvNGu3stfcQ/QlySaqf9x7lTdj73VyjjSgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAghvstOGC1Kk4azMG7DY35a3jwcnX3LV/t327u7bzRtlde2LK3856y8a8acNtbyuppOaWjFbZjO7sj/7AX1tcaPqLJRVmFty1rVOn3LVpz83u2k7JfzAssxu5PuH/2XzT0YZzDb1bs7kSAIK7agiY2VNmNm1mRy557KtmdsLMDnf/+0J/lwmgXzxXAs9IeugKj38jpbS3+1/GxR+A68lVQyCl9JKkswNYC4AhWM17Ak+Y2S+6LxcybtoGcD251hD4pqTdkvZKmpL09V6FZrbfzA6Z2aH2gv9dXQCDcU0hkFI6mVJqp5Q6kr4l6b4Vag+klPallPYVR32/PBHA4FxTCJjZjku+fETSkV61AK5vV20WMrPnJN0vaauZHZf0FUn3m9leSUnSu5Ie7+MaAfTRVUMgpfToFR7+dh/WAmAIBts2XJQa475JqjltmaPH86bVHl30twKXzvpbgZub/WuuvjPirpXy+k4LLf/xsIb/FWHKmDZ84jP+7e56cYO7VpKqKWP/3nf2qUsqztTdtfXt/vNXmfFPt5akyvlld+2Scx2dUu/zQdswEBwhAARHCADBEQJAcIQAEBwhAARHCADBEQJAcIQAEBwhAAQ30LbhkVpTd3z8PVdt45/9k19boxljcCUdfP1Od+3WV/zbTQV/O+vib/pnK4z8xN+6LEnzO/2tsuOv+rdbWvC3L9d2z/trn85ri05F//ku3HGbu7ZTyzjOGZ3q7Urez9rGpP/bsnrW15JsHaYNA+iBEACCIwSA4AgBIDhCAAiOEACCIwSA4AgBIDhCAAiOEACCIwSA4AZ670BzvqJ3fvpRV+3OZtO93fJc3sjxR379sLv2halPuWurp/097ZZxu8PMbv+9AJJUbPhrc8ak17f6e+uL/+ofyd3ZMOeulSRr+Edy6+Rp/3Z3TrprRzLGgs/eWnXXSlL1rP9eiso538m2FcbQcyUABEcIAMERAkBwhAAQHCEABEcIAMERAkBwhAAQHCEABEcIAMENtG1YJiXn31ho+lsnO3kTuXXkvH+cec4w89ppf/vy/KJ/0aWlvLbo1oh/1fO7/e2v2w7713HqnsyTkqEwX3fXpqZ//6zpG98tSfUtG921hRVadldb39zsaylfaUw7VwJAcIQAEBwhAARHCADBEQJAcIQAEBwhAARHCADBEQJAcIQAEJyllNfSuKq/zOyUpGNX+KOtkvxjYW8s63nfJPbvRnFrSmnblf5goCHQi5kdSintG/Y6+mE975vE/q0HvBwAgiMEgOCulxA4MOwF9NF63jeJ/bvhXRfvCQAYnuvlSgDAkBACQHCEABAcIQAERwgAwf0fVo4XRhlUkVUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP6AsgTbBrA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_VdBg6EzfT",
        "colab_type": "code",
        "outputId": "78b64502-9691-4218-90f8-d29ac31843ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention( \"so the sweet spot is between and .\")\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = so the sweet spot is between and .\n",
            "output = . . . . . . . . . . . . . . . . . . . .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpaNLG_FG2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_GdRlFcc8",
        "colab_type": "code",
        "outputId": "cc492739-6496-4e91-aa80-b25f93205a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(attentions.size())"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA24gW3JFz35",
        "colab_type": "code",
        "outputId": "24aea4a9-2700-41d8-8776-ec73b6c7b33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f553191c860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-6wIjIdpVNu",
        "colab_type": "text"
      },
      "source": [
        "1. BiLSTM\n",
        "2. GloVE embedding\n",
        "3. presentation\n",
        "4. BLUE Score and how error is calculated here\n",
        "5. Figure out how attention figures are made.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YOZ1jJGndf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}