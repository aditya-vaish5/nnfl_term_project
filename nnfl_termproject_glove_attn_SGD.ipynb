{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of nnfl_termproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vaish5/nnfl_term_project/blob/master/nnfl_termproject_glove_attn_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uer1xgJvH6L6",
        "colab_type": "code",
        "outputId": "ac5bfdc0-aa79-4576-8578-9fe7cc92dc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 19:06:16--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13603614 (13M) [text/plain]\n",
            "Saving to: ‘train.en.1’\n",
            "\n",
            "\rtrain.en.1            0%[                    ]       0  --.-KB/s               \rtrain.en.1            0%[                    ] 120.00K   503KB/s               \rtrain.en.1            3%[                    ] 472.00K  1.05MB/s               \rtrain.en.1           10%[=>                  ]   1.33M  2.08MB/s               \rtrain.en.1           23%[===>                ]   3.10M  3.70MB/s               \rtrain.en.1           50%[=========>          ]   6.60M  6.30MB/s               \rtrain.en.1           91%[=================>  ]  11.86M  9.51MB/s               \rtrain.en.1          100%[===================>]  12.97M  9.83MB/s    in 1.3s    \n",
            "\n",
            "2020-05-24 19:06:17 (9.83 MB/s) - ‘train.en.1’ saved [13603614/13603614]\n",
            "\n",
            "--2020-05-24 19:06:24--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18074646 (17M) [text/plain]\n",
            "Saving to: ‘train.vi.1’\n",
            "\n",
            "train.vi.1          100%[===================>]  17.24M  11.1MB/s    in 1.6s    \n",
            "\n",
            "2020-05-24 19:06:26 (11.1 MB/s) - ‘train.vi.1’ saved [18074646/18074646]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advDQCZZIi60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLEfKM5Q6hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_to_read = 140000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlaQsvAUO9Jm",
        "colab_type": "code",
        "outputId": "159066b3-be94-4b57-dc9d-786d77ba83a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        }
      },
      "source": [
        "source_sent = []\n",
        "target_sent = []\n",
        "\n",
        "test_source_sent = []\n",
        "test_target_sent = []\n",
        "\n",
        "\n",
        "with open('train.en', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        # discarding first 20 translations as there was some\n",
        "        # english to english translations found in the first few. which are wrong\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        source_sent.append(line)\n",
        "        if len(source_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "with open('train.vi', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        \n",
        "        target_sent.append(line)\n",
        "        if len(target_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
        "\n",
        "print('Sample translations (%d)'%len(source_sent))\n",
        "for i in range(0,sentences_to_read,10000):\n",
        "    print('(',i,') EN: ', source_sent[i])\n",
        "    print('(',i,') VI: ', target_sent[i])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample translations (133267)\n",
            "( 0 ) EN:  In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .\n",
            "\n",
            "( 0 ) VI:  Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học .\n",
            "\n",
            "( 10000 ) EN:  This is an area in the prefrontal cortex , a region where we can use cognition to try to overcome aversive emotional states .\n",
            "\n",
            "( 10000 ) VI:  Đây là một khu vực trong vỏ não trước trán , vùng mà chúng sử dụng tri thức cho việc thử vượt qua trạng thái cảm xúc ác cảm .\n",
            "\n",
            "( 20000 ) EN:  And there are flowers that are self-infertile . That means they can &apos;t -- the pollen in their bloom can &apos;t fertilize themselves .\n",
            "\n",
            "( 20000 ) VI:  có những loài hoa không thể tự thụ phấn . Nghĩa là chúng không thể -- phấn hoa của nó không thể tụ thụ phấn được\n",
            "\n",
            "( 30000 ) EN:  And a lot of this comes together in a philosophy of change that I find really is powerful .\n",
            "\n",
            "( 30000 ) VI:  Và nhiều như vậy hợp lại thành một triết lý của sự thay đổi mà tôi thấy là thực sự rất mạnh .\n",
            "\n",
            "( 40000 ) EN:  Dean Ornish : At first for a long time , I wrote messages in notebooks .\n",
            "\n",
            "( 40000 ) VI:  Dean Ornish : &quot; Trong một khoảng thời gian dài ban đầu , tôi đã viết các tin nhắn trên các cuốn ghi chú .\n",
            "\n",
            "( 50000 ) EN:  World &apos;s first bamboo bike with folding handlebars .\n",
            "\n",
            "( 50000 ) VI:  Chiếc xe đạp bằng tre đầu tiên trên thế giới với ghi đông gập .\n",
            "\n",
            "( 60000 ) EN:  We need to invest more resources into research and treatment of mental illness .\n",
            "\n",
            "( 60000 ) VI:  Chúng ta cần đầu tư nhiều nguồn lực hơn cho công cuộc nghiên cứu và chữa trị về bệnh thần kinh .\n",
            "\n",
            "( 70000 ) EN:  If we are providing knowledge and experience , we need to structure that .\n",
            "\n",
            "( 70000 ) VI:  Nếu chúng ta cung cấp kiến thức và kinh nghiệm , chúng ta cần cơ cấu nó .\n",
            "\n",
            "( 80000 ) EN:  But I say it has to be under the conditions I &apos;ve always worked : no credit , no logos , no sponsoring .\n",
            "\n",
            "( 80000 ) VI:  Nhưng tôi nói nó phải theo các điều kiện tôi luôn luôn làm không có tín dụng , không có biểu tượng , không có tài trợ .\n",
            "\n",
            "( 90000 ) EN:  What would it look like ?\n",
            "\n",
            "( 90000 ) VI:  Nó sẽ trông như thế nào ?\n",
            "\n",
            "( 100000 ) EN:  And the 70 year-old ones , actually they &apos;re better at scouting out the good nesting places , and they also have more progeny every year .\n",
            "\n",
            "( 100000 ) VI:  Và những con 70 tuổi , thực sự giỏi hơn trong việc tìm kiếm một nơi để dựng tổ , và chúng cũng có nhiều con hơn hàng năm\n",
            "\n",
            "( 110000 ) EN:  The next time you dine on sushi -- or sashimi , or swordfish steak , or shrimp cocktail , whatever wildlife you happen to enjoy from the ocean -- think of the real cost .\n",
            "\n",
            "( 110000 ) VI:  Khi bạn thưởng thức sushi , hay sashimi , hay thịt cá kiếm nướng , hay cốc-tai tôm , bất kể thứ gì hoang dã từ đại dương mà bạn thưởng thức , hãy nghĩ về cái giá thực sự phải trả .\n",
            "\n",
            "( 120000 ) EN:  When I laid out my plan , I realized that I faced three main challenges : first , creating a sensor ; second , designing a circuit ; and third , coding a smartphone app .\n",
            "\n",
            "( 120000 ) VI:  Khi lập kế hoạch , tôi nhận ra mình đối mặt với 3 thách thức : thứ nhất , tạo ra một cảm biến ; thứ hai , thiết kế bảng mạch ; thứ ba , lập trình ứng dụng .\n",
            "\n",
            "( 130000 ) EN:  Why would you do something that dangerous ?\n",
            "\n",
            "( 130000 ) VI:  Tại sao bạn lại sẵn sàng làm một việc nguy hiểm như thế ?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlKPSSfRsEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.en') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZTwUWuIgLHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0,len(word_counts),10000):\n",
        "# print(word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs5Q5lQZbv5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e6v96s4b30B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_eng = OrderedDict(sorted(word_counts.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Wqju8hcSDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_eng=list(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKpJjMkfbDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnsHtGAcX36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_engg=sorted_train_eng[0:100000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ug4rNDac-7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_HO75i3cYSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(sorted_train_engg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlz5IzzldMgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.vi') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts_vi = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehg5nQPYdwhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_vi = OrderedDict(sorted(word_counts_vi.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrNkGcOietZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_vii=list(sorted_train_vi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4hmeRUBevmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_vii)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUoCchhiazp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1HkRGqhivpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.vi') as f:\n",
        "#     passage4 = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bgXuFYli7Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# passage4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGiFmExiI5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqNFoSdi8MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "\n",
        "# words_vi = re.findall(r'\\S+', passage4)\n",
        "# words_vi[-3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AMvKjnQjJQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ATG4EKjMPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLbwCAG1nB2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.50K.en') as f:\n",
        "#     passage3 = f.read()\n",
        "# words_en = re.findall(r'\\S+', passage3)\n",
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sua1PaHGabby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "a35a1cf2-6c21-4dc7-918f-fa402586d924"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 19:06:28--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-05-24 19:06:29--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-05-24 19:06:29--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.15MB/s    in 6m 26s  \n",
            "\n",
            "2020-05-24 19:12:55 (2.13 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLpl2TsqnSH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "837a1e8d-60ab-4354-a7e9-eae0277130a6"
      },
      "source": [
        "!apt install gzip\n",
        "import gzip\n",
        "# with gzip.open('/content/glove.6B.txt.gz') as f:\n",
        "#   glove_vec = f.read()\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "gzip is already the newest version (1.6-5ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: nA\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPMhgJkrhdvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "a938fd96-e6d7-48fe-b262-01f34c5a7f93"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6B.50.dat\t glove.6B.100d.txt  glove.6B.50d.txt  sample_data  train.vi\n",
            "6B.50_idx.pkl\t glove.6B.200d.txt  glove.6B.zip      train.en\t   train.vi.1\n",
            "6B.50_words.pkl  glove.6B.300d.txt  glove.6B.zip.1    train.en.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTYl-Iy441aS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7dba37d2-c2ee-4fb0-b7eb-845a562e2e6e"
      },
      "source": [
        "!pip install bcolz"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bcolz in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg7DNhY55rHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bcolz\n",
        "import pickle\n",
        "import copy\n",
        "import operator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iAeOYuy3SYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir='/content/6B.50.dat', mode='w')\n",
        "with open('/content/glove.6B.50d.txt', 'rb') as f:\n",
        "    for l in f:\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vect = np.array(line[1:]).astype(np.float)\n",
        "        vectors.append(vect)\n",
        "     \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400000, 50)), rootdir='/content/6B.50.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open('/content/6B.50_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open('/content/6B.50_idx.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43NKQFrM3ZcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = bcolz.open('/content/6B.50.dat')[:]\n",
        "words = pickle.load(open('/content/6B.50_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open('/content/6B.50_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bDaHSLOG8xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFynSVZCA0QP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "4d0b41bd-07cd-4e79-a8d1-621881111198"
      },
      "source": [
        "glove_dframe = DataFrame(vectors, columns=range(1,51), index=words)\n",
        "glove_dframe[100:110]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>so</th>\n",
              "      <td>0.60308</td>\n",
              "      <td>-0.320240</td>\n",
              "      <td>0.088857</td>\n",
              "      <td>-0.551760</td>\n",
              "      <td>0.531820</td>\n",
              "      <td>0.047069</td>\n",
              "      <td>-0.36246</td>\n",
              "      <td>0.005702</td>\n",
              "      <td>-0.37665</td>\n",
              "      <td>0.225340</td>\n",
              "      <td>-0.13534</td>\n",
              "      <td>0.359880</td>\n",
              "      <td>-0.425180</td>\n",
              "      <td>0.071324</td>\n",
              "      <td>0.770650</td>\n",
              "      <td>0.567120</td>\n",
              "      <td>0.41226</td>\n",
              "      <td>0.124510</td>\n",
              "      <td>0.142300</td>\n",
              "      <td>-0.96535</td>\n",
              "      <td>-0.390530</td>\n",
              "      <td>0.341990</td>\n",
              "      <td>0.56969</td>\n",
              "      <td>0.031635</td>\n",
              "      <td>0.694650</td>\n",
              "      <td>-1.9216</td>\n",
              "      <td>-0.671180</td>\n",
              "      <td>0.57971</td>\n",
              "      <td>0.860880</td>\n",
              "      <td>-0.591050</td>\n",
              "      <td>3.7787</td>\n",
              "      <td>0.304310</td>\n",
              "      <td>-0.043103</td>\n",
              "      <td>-0.42398</td>\n",
              "      <td>-0.063915</td>\n",
              "      <td>-0.066822</td>\n",
              "      <td>0.061983</td>\n",
              "      <td>0.563320</td>\n",
              "      <td>-0.223350</td>\n",
              "      <td>-0.47386</td>\n",
              "      <td>-0.470210</td>\n",
              "      <td>0.091714</td>\n",
              "      <td>0.147780</td>\n",
              "      <td>0.638050</td>\n",
              "      <td>-0.143560</td>\n",
              "      <td>-0.002293</td>\n",
              "      <td>-0.315000</td>\n",
              "      <td>-0.251870</td>\n",
              "      <td>-0.268790</td>\n",
              "      <td>0.36657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>them</th>\n",
              "      <td>0.64642</td>\n",
              "      <td>-0.556000</td>\n",
              "      <td>0.470380</td>\n",
              "      <td>-0.820740</td>\n",
              "      <td>0.795120</td>\n",
              "      <td>0.287710</td>\n",
              "      <td>-0.56426</td>\n",
              "      <td>0.146300</td>\n",
              "      <td>-0.52421</td>\n",
              "      <td>0.021607</td>\n",
              "      <td>-0.11266</td>\n",
              "      <td>0.319860</td>\n",
              "      <td>-0.057542</td>\n",
              "      <td>-0.233750</td>\n",
              "      <td>0.637030</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>0.46490</td>\n",
              "      <td>-0.423980</td>\n",
              "      <td>0.091868</td>\n",
              "      <td>-0.88040</td>\n",
              "      <td>0.220770</td>\n",
              "      <td>0.712700</td>\n",
              "      <td>0.98196</td>\n",
              "      <td>-0.033819</td>\n",
              "      <td>0.315540</td>\n",
              "      <td>-1.8001</td>\n",
              "      <td>-0.260030</td>\n",
              "      <td>-0.37762</td>\n",
              "      <td>0.856340</td>\n",
              "      <td>-1.339300</td>\n",
              "      <td>3.6408</td>\n",
              "      <td>0.872730</td>\n",
              "      <td>-0.792300</td>\n",
              "      <td>-0.51268</td>\n",
              "      <td>0.144150</td>\n",
              "      <td>0.554390</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.132330</td>\n",
              "      <td>-0.071904</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>-0.089989</td>\n",
              "      <td>-0.031932</td>\n",
              "      <td>0.613900</td>\n",
              "      <td>0.404190</td>\n",
              "      <td>0.226860</td>\n",
              "      <td>-0.189740</td>\n",
              "      <td>-0.554030</td>\n",
              "      <td>-0.358310</td>\n",
              "      <td>-0.109950</td>\n",
              "      <td>-0.44700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>what</th>\n",
              "      <td>0.45323</td>\n",
              "      <td>0.059811</td>\n",
              "      <td>-0.105770</td>\n",
              "      <td>-0.333000</td>\n",
              "      <td>0.723590</td>\n",
              "      <td>-0.087170</td>\n",
              "      <td>-0.61053</td>\n",
              "      <td>-0.037695</td>\n",
              "      <td>-0.30945</td>\n",
              "      <td>0.218050</td>\n",
              "      <td>-0.43605</td>\n",
              "      <td>0.473180</td>\n",
              "      <td>-0.768660</td>\n",
              "      <td>-0.271300</td>\n",
              "      <td>1.104200</td>\n",
              "      <td>0.591410</td>\n",
              "      <td>0.56962</td>\n",
              "      <td>-0.186780</td>\n",
              "      <td>0.148670</td>\n",
              "      <td>-0.67292</td>\n",
              "      <td>-0.346720</td>\n",
              "      <td>0.522840</td>\n",
              "      <td>0.22959</td>\n",
              "      <td>-0.072014</td>\n",
              "      <td>0.939670</td>\n",
              "      <td>-2.3985</td>\n",
              "      <td>-1.323800</td>\n",
              "      <td>0.28698</td>\n",
              "      <td>0.755090</td>\n",
              "      <td>-0.765220</td>\n",
              "      <td>3.3425</td>\n",
              "      <td>0.172330</td>\n",
              "      <td>-0.518030</td>\n",
              "      <td>-0.82970</td>\n",
              "      <td>-0.293330</td>\n",
              "      <td>-0.500760</td>\n",
              "      <td>-0.152280</td>\n",
              "      <td>0.098973</td>\n",
              "      <td>0.181460</td>\n",
              "      <td>-0.17420</td>\n",
              "      <td>-0.406660</td>\n",
              "      <td>0.203480</td>\n",
              "      <td>-0.011788</td>\n",
              "      <td>0.482520</td>\n",
              "      <td>0.024598</td>\n",
              "      <td>0.340640</td>\n",
              "      <td>-0.084724</td>\n",
              "      <td>0.532400</td>\n",
              "      <td>-0.251030</td>\n",
              "      <td>0.62546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>him</th>\n",
              "      <td>0.11964</td>\n",
              "      <td>-0.045405</td>\n",
              "      <td>0.051100</td>\n",
              "      <td>-0.828730</td>\n",
              "      <td>0.976650</td>\n",
              "      <td>0.111280</td>\n",
              "      <td>-0.54588</td>\n",
              "      <td>1.156100</td>\n",
              "      <td>-0.68081</td>\n",
              "      <td>0.060207</td>\n",
              "      <td>-0.28765</td>\n",
              "      <td>0.880610</td>\n",
              "      <td>-0.917950</td>\n",
              "      <td>-0.183280</td>\n",
              "      <td>0.841840</td>\n",
              "      <td>-0.118560</td>\n",
              "      <td>-0.14957</td>\n",
              "      <td>-0.161550</td>\n",
              "      <td>-0.374060</td>\n",
              "      <td>-0.45342</td>\n",
              "      <td>-0.185170</td>\n",
              "      <td>1.039200</td>\n",
              "      <td>0.55667</td>\n",
              "      <td>-0.143090</td>\n",
              "      <td>0.713940</td>\n",
              "      <td>-2.9407</td>\n",
              "      <td>-0.051859</td>\n",
              "      <td>-0.13871</td>\n",
              "      <td>0.321510</td>\n",
              "      <td>-0.979710</td>\n",
              "      <td>2.9054</td>\n",
              "      <td>0.534260</td>\n",
              "      <td>-0.814180</td>\n",
              "      <td>-0.48852</td>\n",
              "      <td>0.011175</td>\n",
              "      <td>0.422110</td>\n",
              "      <td>0.390040</td>\n",
              "      <td>0.452430</td>\n",
              "      <td>-0.007067</td>\n",
              "      <td>-0.64889</td>\n",
              "      <td>0.091121</td>\n",
              "      <td>0.468900</td>\n",
              "      <td>-0.581920</td>\n",
              "      <td>0.456540</td>\n",
              "      <td>0.027340</td>\n",
              "      <td>-0.445390</td>\n",
              "      <td>-0.423730</td>\n",
              "      <td>-0.627920</td>\n",
              "      <td>0.024592</td>\n",
              "      <td>-0.14341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>-0.39874</td>\n",
              "      <td>0.071993</td>\n",
              "      <td>-0.069773</td>\n",
              "      <td>0.147060</td>\n",
              "      <td>0.118500</td>\n",
              "      <td>0.147700</td>\n",
              "      <td>-0.84431</td>\n",
              "      <td>0.147600</td>\n",
              "      <td>0.64804</td>\n",
              "      <td>-0.559260</td>\n",
              "      <td>0.50164</td>\n",
              "      <td>-0.073356</td>\n",
              "      <td>-0.412910</td>\n",
              "      <td>-0.536110</td>\n",
              "      <td>0.001539</td>\n",
              "      <td>0.130580</td>\n",
              "      <td>0.41344</td>\n",
              "      <td>-0.469950</td>\n",
              "      <td>-0.395550</td>\n",
              "      <td>0.31692</td>\n",
              "      <td>0.142350</td>\n",
              "      <td>-0.027840</td>\n",
              "      <td>0.15000</td>\n",
              "      <td>0.046728</td>\n",
              "      <td>-0.484600</td>\n",
              "      <td>-2.1998</td>\n",
              "      <td>0.956550</td>\n",
              "      <td>-0.52361</td>\n",
              "      <td>-0.249620</td>\n",
              "      <td>0.071318</td>\n",
              "      <td>3.2888</td>\n",
              "      <td>0.203260</td>\n",
              "      <td>-0.382280</td>\n",
              "      <td>-0.66121</td>\n",
              "      <td>-0.137100</td>\n",
              "      <td>-0.769120</td>\n",
              "      <td>-0.099412</td>\n",
              "      <td>0.212310</td>\n",
              "      <td>-0.990460</td>\n",
              "      <td>-0.48150</td>\n",
              "      <td>0.059310</td>\n",
              "      <td>-0.289030</td>\n",
              "      <td>0.922230</td>\n",
              "      <td>-0.907380</td>\n",
              "      <td>-0.053878</td>\n",
              "      <td>1.055700</td>\n",
              "      <td>-0.983100</td>\n",
              "      <td>0.167570</td>\n",
              "      <td>-0.816590</td>\n",
              "      <td>-0.12107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>during</th>\n",
              "      <td>0.29784</td>\n",
              "      <td>-0.018422</td>\n",
              "      <td>-0.718910</td>\n",
              "      <td>-0.465100</td>\n",
              "      <td>-0.456610</td>\n",
              "      <td>-0.004215</td>\n",
              "      <td>-0.74598</td>\n",
              "      <td>0.346620</td>\n",
              "      <td>-0.51781</td>\n",
              "      <td>-0.587700</td>\n",
              "      <td>0.18398</td>\n",
              "      <td>-0.369030</td>\n",
              "      <td>-0.522250</td>\n",
              "      <td>-0.140820</td>\n",
              "      <td>0.834460</td>\n",
              "      <td>-0.269620</td>\n",
              "      <td>-0.89364</td>\n",
              "      <td>-0.118130</td>\n",
              "      <td>-1.307600</td>\n",
              "      <td>0.47500</td>\n",
              "      <td>0.528150</td>\n",
              "      <td>-0.021974</td>\n",
              "      <td>0.61869</td>\n",
              "      <td>-0.653620</td>\n",
              "      <td>-0.142980</td>\n",
              "      <td>-1.6466</td>\n",
              "      <td>-0.053050</td>\n",
              "      <td>-0.17046</td>\n",
              "      <td>0.170480</td>\n",
              "      <td>0.757560</td>\n",
              "      <td>3.5832</td>\n",
              "      <td>0.137750</td>\n",
              "      <td>-0.378110</td>\n",
              "      <td>-0.48736</td>\n",
              "      <td>0.006991</td>\n",
              "      <td>0.599130</td>\n",
              "      <td>0.314040</td>\n",
              "      <td>0.307340</td>\n",
              "      <td>-0.423970</td>\n",
              "      <td>0.35383</td>\n",
              "      <td>-0.971510</td>\n",
              "      <td>0.160820</td>\n",
              "      <td>-0.636660</td>\n",
              "      <td>-0.204490</td>\n",
              "      <td>-0.070846</td>\n",
              "      <td>-0.322190</td>\n",
              "      <td>-0.049254</td>\n",
              "      <td>-0.418650</td>\n",
              "      <td>-0.689900</td>\n",
              "      <td>-0.54908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>0.30806</td>\n",
              "      <td>-0.296650</td>\n",
              "      <td>-0.257060</td>\n",
              "      <td>-0.587100</td>\n",
              "      <td>0.095135</td>\n",
              "      <td>-0.152110</td>\n",
              "      <td>-0.91478</td>\n",
              "      <td>0.757270</td>\n",
              "      <td>-0.30423</td>\n",
              "      <td>-0.290580</td>\n",
              "      <td>-0.13034</td>\n",
              "      <td>-0.100950</td>\n",
              "      <td>-0.897550</td>\n",
              "      <td>-0.004783</td>\n",
              "      <td>0.800600</td>\n",
              "      <td>0.169630</td>\n",
              "      <td>-0.50634</td>\n",
              "      <td>-0.658420</td>\n",
              "      <td>-1.133900</td>\n",
              "      <td>-0.11095</td>\n",
              "      <td>0.654180</td>\n",
              "      <td>0.353780</td>\n",
              "      <td>0.63650</td>\n",
              "      <td>-0.300830</td>\n",
              "      <td>0.026192</td>\n",
              "      <td>-1.9383</td>\n",
              "      <td>0.690730</td>\n",
              "      <td>0.17019</td>\n",
              "      <td>0.199220</td>\n",
              "      <td>-0.393070</td>\n",
              "      <td>3.4795</td>\n",
              "      <td>0.325460</td>\n",
              "      <td>-0.763140</td>\n",
              "      <td>-0.15125</td>\n",
              "      <td>0.181690</td>\n",
              "      <td>-0.007695</td>\n",
              "      <td>0.555250</td>\n",
              "      <td>0.561420</td>\n",
              "      <td>0.279700</td>\n",
              "      <td>-0.12891</td>\n",
              "      <td>-0.390370</td>\n",
              "      <td>0.004439</td>\n",
              "      <td>-0.323670</td>\n",
              "      <td>0.009888</td>\n",
              "      <td>-0.378660</td>\n",
              "      <td>0.300180</td>\n",
              "      <td>0.208750</td>\n",
              "      <td>-0.538440</td>\n",
              "      <td>-0.110580</td>\n",
              "      <td>-0.54785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>may</th>\n",
              "      <td>0.70480</td>\n",
              "      <td>0.222610</td>\n",
              "      <td>0.086997</td>\n",
              "      <td>-0.212410</td>\n",
              "      <td>-0.089356</td>\n",
              "      <td>0.437420</td>\n",
              "      <td>-0.28170</td>\n",
              "      <td>0.133780</td>\n",
              "      <td>-0.50859</td>\n",
              "      <td>-0.182420</td>\n",
              "      <td>0.49506</td>\n",
              "      <td>0.424610</td>\n",
              "      <td>0.046785</td>\n",
              "      <td>-0.501210</td>\n",
              "      <td>0.846210</td>\n",
              "      <td>1.014600</td>\n",
              "      <td>-0.43954</td>\n",
              "      <td>-0.654990</td>\n",
              "      <td>-0.647060</td>\n",
              "      <td>-0.23365</td>\n",
              "      <td>0.276120</td>\n",
              "      <td>-0.632940</td>\n",
              "      <td>0.91064</td>\n",
              "      <td>0.033327</td>\n",
              "      <td>-0.058451</td>\n",
              "      <td>-1.6059</td>\n",
              "      <td>-0.347410</td>\n",
              "      <td>-0.36285</td>\n",
              "      <td>0.467230</td>\n",
              "      <td>0.244000</td>\n",
              "      <td>3.4249</td>\n",
              "      <td>0.056168</td>\n",
              "      <td>-0.719910</td>\n",
              "      <td>-0.88332</td>\n",
              "      <td>0.337410</td>\n",
              "      <td>-0.532360</td>\n",
              "      <td>0.339910</td>\n",
              "      <td>0.023837</td>\n",
              "      <td>0.238400</td>\n",
              "      <td>-0.38713</td>\n",
              "      <td>-0.496210</td>\n",
              "      <td>-0.148460</td>\n",
              "      <td>0.046201</td>\n",
              "      <td>0.103250</td>\n",
              "      <td>0.173740</td>\n",
              "      <td>0.137630</td>\n",
              "      <td>0.084989</td>\n",
              "      <td>-0.396880</td>\n",
              "      <td>0.176320</td>\n",
              "      <td>0.31862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>since</th>\n",
              "      <td>0.15423</td>\n",
              "      <td>-0.125520</td>\n",
              "      <td>0.022279</td>\n",
              "      <td>-0.067561</td>\n",
              "      <td>-0.359750</td>\n",
              "      <td>0.144090</td>\n",
              "      <td>-1.09020</td>\n",
              "      <td>-0.028693</td>\n",
              "      <td>-0.43147</td>\n",
              "      <td>-0.137810</td>\n",
              "      <td>0.37841</td>\n",
              "      <td>-0.630310</td>\n",
              "      <td>-0.955200</td>\n",
              "      <td>-0.200590</td>\n",
              "      <td>1.261300</td>\n",
              "      <td>0.355060</td>\n",
              "      <td>-0.48844</td>\n",
              "      <td>-0.110500</td>\n",
              "      <td>-0.994670</td>\n",
              "      <td>0.56709</td>\n",
              "      <td>0.014872</td>\n",
              "      <td>-0.108730</td>\n",
              "      <td>0.41999</td>\n",
              "      <td>-0.251970</td>\n",
              "      <td>-0.423850</td>\n",
              "      <td>-1.6795</td>\n",
              "      <td>0.021355</td>\n",
              "      <td>-0.11534</td>\n",
              "      <td>0.010638</td>\n",
              "      <td>0.913050</td>\n",
              "      <td>3.6854</td>\n",
              "      <td>-0.117510</td>\n",
              "      <td>-0.093662</td>\n",
              "      <td>-0.43435</td>\n",
              "      <td>0.013842</td>\n",
              "      <td>-0.183450</td>\n",
              "      <td>0.040666</td>\n",
              "      <td>0.397880</td>\n",
              "      <td>-0.336220</td>\n",
              "      <td>-0.20412</td>\n",
              "      <td>-1.131900</td>\n",
              "      <td>-0.123220</td>\n",
              "      <td>-0.242990</td>\n",
              "      <td>-0.112860</td>\n",
              "      <td>-0.557860</td>\n",
              "      <td>0.118930</td>\n",
              "      <td>-0.439170</td>\n",
              "      <td>-0.285070</td>\n",
              "      <td>-0.630300</td>\n",
              "      <td>-0.58676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>many</th>\n",
              "      <td>0.69790</td>\n",
              "      <td>0.082340</td>\n",
              "      <td>0.041526</td>\n",
              "      <td>-0.507040</td>\n",
              "      <td>-0.158010</td>\n",
              "      <td>0.360480</td>\n",
              "      <td>-1.07450</td>\n",
              "      <td>-0.239270</td>\n",
              "      <td>-0.74704</td>\n",
              "      <td>0.160070</td>\n",
              "      <td>-0.18420</td>\n",
              "      <td>-0.079723</td>\n",
              "      <td>0.320440</td>\n",
              "      <td>-0.203260</td>\n",
              "      <td>0.595910</td>\n",
              "      <td>-0.067483</td>\n",
              "      <td>0.34272</td>\n",
              "      <td>-0.054553</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>-1.02850</td>\n",
              "      <td>-0.019078</td>\n",
              "      <td>0.065302</td>\n",
              "      <td>0.42329</td>\n",
              "      <td>0.456240</td>\n",
              "      <td>0.205530</td>\n",
              "      <td>-1.2436</td>\n",
              "      <td>-1.189500</td>\n",
              "      <td>-0.66457</td>\n",
              "      <td>-0.049265</td>\n",
              "      <td>-0.267790</td>\n",
              "      <td>4.0103</td>\n",
              "      <td>0.445700</td>\n",
              "      <td>0.404230</td>\n",
              "      <td>-1.06010</td>\n",
              "      <td>0.282900</td>\n",
              "      <td>0.367240</td>\n",
              "      <td>-0.400970</td>\n",
              "      <td>-0.043859</td>\n",
              "      <td>-0.509930</td>\n",
              "      <td>0.39467</td>\n",
              "      <td>-0.687130</td>\n",
              "      <td>0.193180</td>\n",
              "      <td>0.463370</td>\n",
              "      <td>0.917070</td>\n",
              "      <td>0.495510</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>-0.867410</td>\n",
              "      <td>0.037265</td>\n",
              "      <td>-0.604430</td>\n",
              "      <td>-0.64699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1         2         3   ...        48        49       50\n",
              "so      0.60308 -0.320240  0.088857  ... -0.251870 -0.268790  0.36657\n",
              "them    0.64642 -0.556000  0.470380  ... -0.358310 -0.109950 -0.44700\n",
              "what    0.45323  0.059811 -0.105770  ...  0.532400 -0.251030  0.62546\n",
              "him     0.11964 -0.045405  0.051100  ... -0.627920  0.024592 -0.14341\n",
              "united -0.39874  0.071993 -0.069773  ...  0.167570 -0.816590 -0.12107\n",
              "during  0.29784 -0.018422 -0.718910  ... -0.418650 -0.689900 -0.54908\n",
              "before  0.30806 -0.296650 -0.257060  ... -0.538440 -0.110580 -0.54785\n",
              "may     0.70480  0.222610  0.086997  ... -0.396880  0.176320  0.31862\n",
              "since   0.15423 -0.125520  0.022279  ... -0.285070 -0.630300 -0.58676\n",
              "many    0.69790  0.082340  0.041526  ...  0.037265 -0.604430 -0.64699\n",
              "\n",
              "[10 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zinJ-_AHHKeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for moving 'sos' token at index 0 and 'eos' token at index 1\n",
        " \n",
        "sos_index = word2idx['sos']\n",
        "eos_index = word2idx['eos']\n",
        "sos_swap_word = words[0]\n",
        "eos_swap_word = words[1]\n",
        " \n",
        "words[0], words[sos_index] = words[sos_index], words[0]\n",
        "words[1], words[eos_index] = words[eos_index], words[1]\n",
        "word2idx[sos_swap_word], word2idx['SOS'] = word2idx['sos'], word2idx[sos_swap_word]\n",
        "word2idx[eos_swap_word], word2idx['EOS'] = word2idx['eos'], word2idx[eos_swap_word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe4FYf23HPlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort Word2idx\n",
        "word2idx = { k : v for k , v in sorted(word2idx.items(), key=operator.itemgetter(1))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzeFp9C7oiR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f = open('glove.6B.50d.txt', encoding= 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7goKXdeppd5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dic = {}\n",
        "# for line in f:\n",
        "#   v = line.split()\n",
        "#   word = v[0]\n",
        "#   vec = np.asarray(v[1:],dtype = 'float32')\n",
        "#   dic[word] = vec\n",
        "# f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjE1_f4npjRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(dic))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lNJeFkqlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove_dic =  OrderedDict(dic.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLAYvUjrjIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0, len(glove_dic) ,10000):\n",
        "#   print(glove_dic[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbt9pD6hr2IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAR8kXzRsMjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = itertools.islice(dic.items(), 0, len(dic),40000)\n",
        "\n",
        "# for key, value in x:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmru76M6nSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYX8cLWV7cPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRMBYLJ7GfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_eng_word(dic,word):\n",
        "#   try:\n",
        "#     x = dic[word]\n",
        "#     return x\n",
        "#   except KeyError:\n",
        "#     return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqLBLDM9T8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# eng_dict = {};\n",
        "# for w in sorted:\n",
        "#   eng_dict[w] = return_embedding_for_eng_word(dic,w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P63YsX9O9niK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eng_vects = itertools.islice(eng_dict.items(), 0, len(eng_dict),10000)\n",
        "\n",
        "# for key, value in eng_vects:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhG4fdR92Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(eng_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esjrjhm9_YXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_vietnamese_word():\n",
        "#   return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kATDp4v__t_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(words4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCHgN2Hi_x_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# viet_dict = {}\n",
        "# for w in words4:\n",
        "#   viet_dict[w] = return_embedding_for_vietnamese_word()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaUn80e2BZXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZDxdLL5klY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uH_VuWD5lvI",
        "colab_type": "code",
        "outputId": "03fe1ff4-2709-4c98-f60a-c3fc3d7be01e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDp726q5pWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        if(name == 'eng'):\n",
        "          self.word2index = { k : v for k , v in sorted(word2idx.items(), key=operator.itemgetter(1))}\n",
        "          self.word2count = { word : 1 for word in words }\n",
        "          self.index2word = { i : word for word, i in word2idx.items() }\n",
        "          self.n_words = 400001\n",
        "        else:\n",
        "          self.word2index = {}\n",
        "          self.word2count = {}\n",
        "          self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "          self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tAZFIx5sAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMVraBNFfmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH \n",
        "        # and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br-e3-7E6EoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    pairs = [];\n",
        "    for i in range(0,len(target_sent)):\n",
        "      pairs.append([normalizeString(source_sent[i]) ,normalizeString(target_sent[i])])\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rJpzUK52MeJ",
        "colab_type": "code",
        "outputId": "4ac542b6-e892-49d4-ad45-ca5a2ced917c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'vi')\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 133267 sentence pairs\n",
            "Trimmed to 66499 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 401035\n",
            "vi 7837\n",
            "['look at the client base for this .', 'hay nhin vao so lieu nguoi su dung e thay ieu nay .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLyqU3WF700M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.input_size = input_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, bidirectional = True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell_state):\n",
        "        # print(\"forward running\")\n",
        "        # print(self.embedding(input).size())\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        # print(output.size())\n",
        "        # output, (hidden, cell_state) = self.lstm(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "        # print(output.size())\n",
        "        return output, hidden, cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "      return torch.zeros(2, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9UdlQE759q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIS CLASS ISN'T USED IN EVALUATION\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(hidden_size*2, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden,cell_state):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden,cell_state = self.lstm(output, (hidden,cell_state))\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden,cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PotAA8uQ7_aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell_state, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        # print(attn_weights.unsqueeze(0).size(), encoder_outputs.unsqueeze(0).size())\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "        # print(embedded[0].size(),attn_applied[0].size())\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, cell_state, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVvbet88DNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZThP3EA8HRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder.initcellstate()\n",
        "    # print(\"setting optimizers to zero grad\")\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    # print(\"INPUT SIZE: \", input_tensor.size())\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      # print(\"starting encoder for \" , ei)\n",
        "      encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "          input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "      # print(encoder_output)\n",
        "      encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    for di in range(target_length):\n",
        "      # print(\"decoder for di : \", di)\n",
        "      decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "          decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "          break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2Gamqd8JiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdSWSxdv8NF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # print(\"train Iter optimizers set\")\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    # print(\"training pairs for this iteration have been assigned\")\n",
        "    # print(\"training pairs size\")\n",
        "    # print(len(training_pairs))\n",
        "    # print(len(training_pairs[0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(training_pairs[0][0])\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        # print(iter , \" : printing iter-1 th training pair\")\n",
        "        # print(training_pair)\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        # print(iter , \" : started training with above tensors\")\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        # print(iter,\" : current iter ended\");\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDY5Z2G8g5L",
        "colab_type": "code",
        "outputId": "17e2323e-5520-44ec-d732-afb7f5d77880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 50\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "print(\"Encoder initialization done\")\n",
        "# attn_decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "print(\"Decoder initialization done\")\n",
        "\n",
        "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "trainIters(encoder1, attn_decoder1, 50, print_every=1)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder initialization done\n",
            "Decoder initialization done\n",
            "0m 0s (- 0m 3s) (1 2%) 8.9435\n",
            "0m 0s (- 0m 3s) (2 4%) 8.9772\n",
            "0m 0s (- 0m 4s) (3 6%) 8.9442\n",
            "0m 0s (- 0m 4s) (4 8%) 8.9488\n",
            "0m 0s (- 0m 3s) (5 10%) 8.9522\n",
            "0m 0s (- 0m 3s) (6 12%) 8.9520\n",
            "0m 0s (- 0m 3s) (7 14%) 5.2001\n",
            "0m 0s (- 0m 3s) (8 16%) 4.8971\n",
            "0m 0s (- 0m 3s) (9 18%) 5.1898\n",
            "0m 0s (- 0m 3s) (10 20%) 4.4752\n",
            "0m 0s (- 0m 3s) (11 22%) 6.9536\n",
            "0m 0s (- 0m 3s) (12 24%) 8.8770\n",
            "0m 1s (- 0m 3s) (13 26%) 3.6829\n",
            "0m 1s (- 0m 2s) (14 28%) 1.8891\n",
            "0m 1s (- 0m 2s) (15 30%) 5.5168\n",
            "0m 1s (- 0m 2s) (16 32%) 1.9840\n",
            "0m 1s (- 0m 2s) (17 34%) 8.9119\n",
            "0m 1s (- 0m 2s) (18 36%) 1.9906\n",
            "0m 1s (- 0m 2s) (19 38%) 8.9498\n",
            "0m 1s (- 0m 2s) (20 40%) 4.1219\n",
            "0m 1s (- 0m 2s) (21 42%) 6.7503\n",
            "0m 1s (- 0m 2s) (22 44%) 4.4761\n",
            "0m 1s (- 0m 2s) (23 46%) 1.8806\n",
            "0m 1s (- 0m 2s) (24 48%) 4.0412\n",
            "0m 1s (- 0m 1s) (25 50%) 3.9903\n",
            "0m 1s (- 0m 1s) (26 52%) 1.7873\n",
            "0m 2s (- 0m 1s) (27 54%) 2.2343\n",
            "0m 2s (- 0m 1s) (28 56%) 6.3475\n",
            "0m 2s (- 0m 1s) (29 57%) 4.4898\n",
            "0m 2s (- 0m 1s) (30 60%) 4.0632\n",
            "0m 2s (- 0m 1s) (31 62%) 4.4449\n",
            "0m 2s (- 0m 1s) (32 64%) 6.3778\n",
            "0m 2s (- 0m 1s) (33 66%) 6.6658\n",
            "0m 2s (- 0m 1s) (34 68%) 2.0984\n",
            "0m 2s (- 0m 1s) (35 70%) 2.8265\n",
            "0m 2s (- 0m 1s) (36 72%) 2.3818\n",
            "0m 2s (- 0m 0s) (37 74%) 2.0871\n",
            "0m 2s (- 0m 0s) (38 76%) 3.2557\n",
            "0m 2s (- 0m 0s) (39 78%) 3.7087\n",
            "0m 2s (- 0m 0s) (40 80%) 2.7313\n",
            "0m 2s (- 0m 0s) (41 82%) 2.8225\n",
            "0m 2s (- 0m 0s) (42 84%) 1.8910\n",
            "0m 3s (- 0m 0s) (43 86%) 0.9413\n",
            "0m 3s (- 0m 0s) (44 88%) 2.7430\n",
            "0m 3s (- 0m 0s) (45 90%) 5.6258\n",
            "0m 3s (- 0m 0s) (46 92%) 3.1772\n",
            "0m 3s (- 0m 0s) (47 94%) 7.4122\n",
            "0m 3s (- 0m 0s) (48 96%) 2.4892\n",
            "0m 3s (- 0m 0s) (49 98%) 2.1000\n",
            "0m 3s (- 0m 0s) (50 100%) 8.8571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm8ns1zoJB-W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCEHLIb8Qnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS9We9ZU8bre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder.initcellstate()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden,encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden,encoder_cell)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = encoder_cell\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden,decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden,decoder_cell, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1dYNPb8eHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vca5iI5L0BRw",
        "colab_type": "code",
        "outputId": "81ae9354-6ad3-4265-b2e7-16764d440c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(input_lang.n_words)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DXfF12H8rNL",
        "colab_type": "code",
        "outputId": "2c86eb6a-c57e-485f-9b10-c473a3316af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> ahhhh .\n",
            "= ahhhh .\n",
            "< . . <EOS>\n",
            "\n",
            "> and nobody read it except for my mom .\n",
            "= va khong co ai oc tru me toi .\n",
            "< <EOS>\n",
            "\n",
            "> anybody got any clues ? ski . right .\n",
            "= ai co goi y nao khong ? truot tuyet . ung roi .\n",
            "< . . . <EOS>\n",
            "\n",
            "> thank you .\n",
            "= xin cam on .\n",
            "< <EOS>\n",
            "\n",
            "> they apos d got a zero . i gave them a test .\n",
            "= may nhoc at . toi a cho may em lam bai kiem tra .\n",
            "< <EOS>\n",
            "\n",
            "> my home network prettyflyforawifi which i think is a great name .\n",
            "= mang nha toi prettyflyforawifi . toi nghi o la mot cai ten an tuong .\n",
            "< <EOS>\n",
            "\n",
            "> there are lots of people who are frustrated .\n",
            "= co rat nhieu nguoi ang that vong .\n",
            "< <EOS>\n",
            "\n",
            "> let me take you to the real china .\n",
            "=  e toi ua quy vi en tq that su\n",
            "< <EOS>\n",
            "\n",
            "> and the same for and and so on .\n",
            "= va tuong tu cho roi v .v .\n",
            "< <EOS>\n",
            "\n",
            "> the area of the brain for sadness is on red hot .\n",
            "= khu vuc cua noi buon co mau o nong .\n",
            "< <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WOs79j0BY_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icCvahalHOMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWda4e48FLT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "# import matplotlib.ticker as ticker\n",
        "# import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKVX8GNBzeR",
        "colab_type": "code",
        "outputId": "d7493814-ac79-454e-fb82-66251202ff26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"so the sweet spot is between and .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3bab561fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP6AsgTbBrA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_VdBg6EzfT",
        "colab_type": "code",
        "outputId": "bcefb478-647f-4bb3-8332-b246de9701ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention( \"so the sweet spot is between and .\")\n"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = so the sweet spot is between and .\n",
            "output = <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpaNLG_FG2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_GdRlFcc8",
        "colab_type": "code",
        "outputId": "0a46be84-b94c-48ef-aa00-29d6a44ea90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(attentions.size())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA24gW3JFz35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-6wIjIdpVNu",
        "colab_type": "text"
      },
      "source": [
        "1. BiLSTM\n",
        "2. GloVE embedding\n",
        "3. presentation\n",
        "4. BLUE Score and how error is calculated here\n",
        "5. Figure out how attention figures are made.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YOZ1jJGndf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}