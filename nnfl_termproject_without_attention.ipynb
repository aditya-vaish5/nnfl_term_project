{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnfl_termproject_without_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-vaish5/nnfl_term_project/blob/master/nnfl_termproject_without_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uer1xgJvH6L6",
        "colab_type": "code",
        "outputId": "d31e8fbb-d2d7-4c2b-8741-fca6a18becc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 09:47:03--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13603614 (13M) [text/plain]\n",
            "Saving to: ‘train.en’\n",
            "\n",
            "train.en            100%[===================>]  12.97M  7.26MB/s    in 1.8s    \n",
            "\n",
            "2020-05-24 09:47:05 (7.26 MB/s) - ‘train.en’ saved [13603614/13603614]\n",
            "\n",
            "--2020-05-24 09:47:08--  https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18074646 (17M) [text/plain]\n",
            "Saving to: ‘train.vi’\n",
            "\n",
            "train.vi            100%[===================>]  17.24M  9.26MB/s    in 1.9s    \n",
            "\n",
            "2020-05-24 09:47:10 (9.26 MB/s) - ‘train.vi’ saved [18074646/18074646]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advDQCZZIi60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLEfKM5Q6hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_to_read = 140000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlaQsvAUO9Jm",
        "colab_type": "code",
        "outputId": "987c5c08-0860-4e40-a13e-1bf70d449233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "source": [
        "source_sent = []\n",
        "target_sent = []\n",
        "\n",
        "test_source_sent = []\n",
        "test_target_sent = []\n",
        "\n",
        "\n",
        "with open('train.en', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        # discarding first 20 translations as there was some\n",
        "        # english to english translations found in the first few. which are wrong\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        source_sent.append(line)\n",
        "        if len(source_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "with open('train.vi', encoding='utf-8') as f:\n",
        "    for l_i, line in enumerate(f):\n",
        "        if l_i<50:\n",
        "            continue\n",
        "        \n",
        "        target_sent.append(line)\n",
        "        if len(target_sent)>=sentences_to_read:\n",
        "            break\n",
        "        \n",
        "            \n",
        "assert len(source_sent)==len(target_sent),'Source: %d, Target: %d'%(len(source_sent),len(target_sent))\n",
        "\n",
        "print('Sample translations (%d)'%len(source_sent))\n",
        "for i in range(0,sentences_to_read,10000):\n",
        "    print('(',i,') EN: ', source_sent[i])\n",
        "    print('(',i,') VI: ', target_sent[i])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample translations (133267)\n",
            "( 0 ) EN:  In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .\n",
            "\n",
            "( 0 ) VI:  Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học .\n",
            "\n",
            "( 10000 ) EN:  This is an area in the prefrontal cortex , a region where we can use cognition to try to overcome aversive emotional states .\n",
            "\n",
            "( 10000 ) VI:  Đây là một khu vực trong vỏ não trước trán , vùng mà chúng sử dụng tri thức cho việc thử vượt qua trạng thái cảm xúc ác cảm .\n",
            "\n",
            "( 20000 ) EN:  And there are flowers that are self-infertile . That means they can &apos;t -- the pollen in their bloom can &apos;t fertilize themselves .\n",
            "\n",
            "( 20000 ) VI:  có những loài hoa không thể tự thụ phấn . Nghĩa là chúng không thể -- phấn hoa của nó không thể tụ thụ phấn được\n",
            "\n",
            "( 30000 ) EN:  And a lot of this comes together in a philosophy of change that I find really is powerful .\n",
            "\n",
            "( 30000 ) VI:  Và nhiều như vậy hợp lại thành một triết lý của sự thay đổi mà tôi thấy là thực sự rất mạnh .\n",
            "\n",
            "( 40000 ) EN:  Dean Ornish : At first for a long time , I wrote messages in notebooks .\n",
            "\n",
            "( 40000 ) VI:  Dean Ornish : &quot; Trong một khoảng thời gian dài ban đầu , tôi đã viết các tin nhắn trên các cuốn ghi chú .\n",
            "\n",
            "( 50000 ) EN:  World &apos;s first bamboo bike with folding handlebars .\n",
            "\n",
            "( 50000 ) VI:  Chiếc xe đạp bằng tre đầu tiên trên thế giới với ghi đông gập .\n",
            "\n",
            "( 60000 ) EN:  We need to invest more resources into research and treatment of mental illness .\n",
            "\n",
            "( 60000 ) VI:  Chúng ta cần đầu tư nhiều nguồn lực hơn cho công cuộc nghiên cứu và chữa trị về bệnh thần kinh .\n",
            "\n",
            "( 70000 ) EN:  If we are providing knowledge and experience , we need to structure that .\n",
            "\n",
            "( 70000 ) VI:  Nếu chúng ta cung cấp kiến thức và kinh nghiệm , chúng ta cần cơ cấu nó .\n",
            "\n",
            "( 80000 ) EN:  But I say it has to be under the conditions I &apos;ve always worked : no credit , no logos , no sponsoring .\n",
            "\n",
            "( 80000 ) VI:  Nhưng tôi nói nó phải theo các điều kiện tôi luôn luôn làm không có tín dụng , không có biểu tượng , không có tài trợ .\n",
            "\n",
            "( 90000 ) EN:  What would it look like ?\n",
            "\n",
            "( 90000 ) VI:  Nó sẽ trông như thế nào ?\n",
            "\n",
            "( 100000 ) EN:  And the 70 year-old ones , actually they &apos;re better at scouting out the good nesting places , and they also have more progeny every year .\n",
            "\n",
            "( 100000 ) VI:  Và những con 70 tuổi , thực sự giỏi hơn trong việc tìm kiếm một nơi để dựng tổ , và chúng cũng có nhiều con hơn hàng năm\n",
            "\n",
            "( 110000 ) EN:  The next time you dine on sushi -- or sashimi , or swordfish steak , or shrimp cocktail , whatever wildlife you happen to enjoy from the ocean -- think of the real cost .\n",
            "\n",
            "( 110000 ) VI:  Khi bạn thưởng thức sushi , hay sashimi , hay thịt cá kiếm nướng , hay cốc-tai tôm , bất kể thứ gì hoang dã từ đại dương mà bạn thưởng thức , hãy nghĩ về cái giá thực sự phải trả .\n",
            "\n",
            "( 120000 ) EN:  When I laid out my plan , I realized that I faced three main challenges : first , creating a sensor ; second , designing a circuit ; and third , coding a smartphone app .\n",
            "\n",
            "( 120000 ) VI:  Khi lập kế hoạch , tôi nhận ra mình đối mặt với 3 thách thức : thứ nhất , tạo ra một cảm biến ; thứ hai , thiết kế bảng mạch ; thứ ba , lập trình ứng dụng .\n",
            "\n",
            "( 130000 ) EN:  Why would you do something that dangerous ?\n",
            "\n",
            "( 130000 ) VI:  Tại sao bạn lại sẵn sàng làm một việc nguy hiểm như thế ?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlKPSSfRsEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.en') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZTwUWuIgLHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0,len(word_counts),10000):\n",
        "# print(word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs5Q5lQZbv5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e6v96s4b30B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_eng = OrderedDict(sorted(word_counts.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Wqju8hcSDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_eng=list(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKpJjMkfbDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnsHtGAcX36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_engg=sorted_train_eng[0:100000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ug4rNDac-7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_HO75i3cYSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(sorted_train_engg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlz5IzzldMgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# with open('train.vi') as f:\n",
        "#     passage = f.read()\n",
        "\n",
        "# words = re.findall(r'\\S+', passage)\n",
        "\n",
        "# cap_words = [word.upper() for word in words]\n",
        "\n",
        "# word_counts_vi = Counter(cap_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehg5nQPYdwhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from collections import OrderedDict\n",
        "# sorted_train_vi = OrderedDict(sorted(word_counts_vi.items(), key = lambda kv : kv[1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrNkGcOietZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted_train_vii=list(sorted_train_vi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4hmeRUBevmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(sorted_train_vii)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUoCchhiazp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1HkRGqhivpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.vi') as f:\n",
        "#     passage4 = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bgXuFYli7Fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# passage4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGiFmExiI5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqNFoSdi8MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import re\n",
        "\n",
        "# words_vi = re.findall(r'\\S+', passage4)\n",
        "# words_vi[-3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AMvKjnQjJQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ATG4EKjMPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLbwCAG1nB2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.50K.en') as f:\n",
        "#     passage3 = f.read()\n",
        "# words_en = re.findall(r'\\S+', passage3)\n",
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sua1PaHGabby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLpl2TsqnSH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !apt install gzip\n",
        "# # import gzip\n",
        "# # with gzip.open('/content/glove.6B.txt.gz') as f:\n",
        "# #   glove_vec = f.read()\n",
        "# !unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPMhgJkrhdvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzeFp9C7oiR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f = open('glove.6B.50d.txt', encoding= 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7goKXdeppd5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dic = {}\n",
        "# for line in f:\n",
        "#   v = line.split()\n",
        "#   word = v[0]\n",
        "#   vec = np.asarray(v[1:],dtype = 'float32')\n",
        "#   dic[word] = vec\n",
        "# f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjE1_f4npjRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(dic))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lNJeFkqlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove_dic =  OrderedDict(dic.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGLAYvUjrjIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # for i in range(0, len(glove_dic) ,10000):\n",
        "#   print(glove_dic[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbt9pD6hr2IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAR8kXzRsMjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = itertools.islice(dic.items(), 0, len(dic),40000)\n",
        "\n",
        "# for key, value in x:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmru76M6nSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(words3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYX8cLWV7cPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRMBYLJ7GfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_eng_word(dic,word):\n",
        "#   try:\n",
        "#     x = dic[word]\n",
        "#     return x\n",
        "#   except KeyError:\n",
        "#     return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqLBLDM9T8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# eng_dict = {};\n",
        "# for w in sorted:\n",
        "#   eng_dict[w] = return_embedding_for_eng_word(dic,w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P63YsX9O9niK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eng_vects = itertools.islice(eng_dict.items(), 0, len(eng_dict),10000)\n",
        "\n",
        "# for key, value in eng_vects:\n",
        "#   print (key, value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhG4fdR92Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(eng_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esjrjhm9_YXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def return_embedding_for_vietnamese_word():\n",
        "#   return np.random.normal(0,2,50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kATDp4v__t_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(words4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCHgN2Hi_x_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# viet_dict = {}\n",
        "# for w in words4:\n",
        "#   viet_dict[w] = return_embedding_for_vietnamese_word()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaUn80e2BZXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZDxdLL5klY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uH_VuWD5lvI",
        "colab_type": "code",
        "outputId": "1f53d09b-7030-4cab-b05d-d8bab4f8cd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhDp726q5pWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tAZFIx5sAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMVraBNFfmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH \n",
        "        # and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br-e3-7E6EoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    pairs = [];\n",
        "    for i in range(0,len(target_sent)):\n",
        "      pairs.append([normalizeString(source_sent[i]) ,normalizeString(target_sent[i])])\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rJpzUK52MeJ",
        "colab_type": "code",
        "outputId": "f248136f-6be4-4419-8b36-f5c10aa64ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'vi')\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 133267 sentence pairs\n",
            "Trimmed to 66499 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 23610\n",
            "vi 7837\n",
            "['we apos re still lighting something on fire every time we want energy .', 'chung ta van ang thap sang bang lua moi khi can nang luong .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLyqU3WF700M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # self.input_size = input_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, bidirectional = True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell_state):\n",
        "        # print(\"forward running\")\n",
        "        # print(self.embedding(input).size())\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        # print(output.size())\n",
        "        # output, (hidden, cell_state) = self.lstm(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "        # print(output.size())\n",
        "        return output, hidden, cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "      return torch.zeros(2, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9UdlQE759q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THIS CLASS ISN'T USED IN EVALUATION\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.output_size = output_size\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(hidden_size*2, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden,cell_state):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "        output = F.relu(output)\n",
        "        output, (hidden,cell_state) = self.lstm(output, (hidden,cell_state))\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden,cell_state\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PotAA8uQ7_aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size,bidirectional =True)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell_state, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        # print(attn_weights.unsqueeze(0).size(), encoder_outputs.unsqueeze(0).size())\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "        # print(embedded[0].size(),attn_applied[0].size())\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell_state) = self.lstm(output, (hidden, cell_state))\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, cell_state, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size, device = device)\n",
        "    def initcellstate(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVvbet88DNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZThP3EA8HRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder.initcellstate()\n",
        "    # print(\"setting optimizers to zero grad\")\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    # print(\"INPUT SIZE: \", input_tensor.size())\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      # print(\"starting encoder for \" , ei)\n",
        "      encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "          input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "      # print(encoder_output)\n",
        "      # encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = encoder_cell\n",
        "    for di in range(target_length):\n",
        "      # print(\"decoder for di : \", di)\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "          decoder_input, decoder_hidden, decoder_cell)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "          break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2Gamqd8JiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdSWSxdv8NF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # print(\"train Iter optimizers set\")\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    # print(\"training pairs for this iteration have been assigned\")\n",
        "    # print(\"training pairs size\")\n",
        "    # print(len(training_pairs))\n",
        "    # print(len(training_pairs[0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(len(training_pairs[0][0]))\n",
        "    # print(training_pairs[0][0])\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        # print(iter , \" : printing iter-1 th training pair\")\n",
        "        # print(training_pair)\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        # print(iter , \" : started training with above tensors\")\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        # print(iter,\" : current iter ended\");\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCEHLIb8Qnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDY5Z2G8g5L",
        "colab_type": "code",
        "outputId": "04e59c48-b829-4da5-91d9-94e1460531cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 100\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "print(\"Encoder initialization done\")\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "print(\"Decoder initialization done\")\n",
        "\n",
        "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "trainIters(encoder1, decoder1, 50, print_every=1)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder initialization done\n",
            "Decoder initialization done\n",
            "0m 0s (- 0m 1s) (1 2%) 8.9331\n",
            "0m 0s (- 0m 1s) (2 4%) 9.0303\n",
            "0m 0s (- 0m 1s) (3 6%) 3.1734\n",
            "0m 0s (- 0m 1s) (4 8%) 8.9684\n",
            "0m 0s (- 0m 1s) (5 10%) 8.9394\n",
            "0m 0s (- 0m 1s) (6 12%) 8.9234\n",
            "0m 0s (- 0m 1s) (7 14%) 1.8936\n",
            "0m 0s (- 0m 1s) (8 16%) 3.0028\n",
            "0m 0s (- 0m 1s) (9 18%) 4.8430\n",
            "0m 0s (- 0m 1s) (10 20%) 2.9693\n",
            "0m 0s (- 0m 1s) (11 22%) 5.1217\n",
            "0m 0s (- 0m 1s) (12 24%) 3.4340\n",
            "0m 0s (- 0m 1s) (13 26%) 2.6376\n",
            "0m 0s (- 0m 1s) (14 28%) 3.5599\n",
            "0m 0s (- 0m 1s) (15 30%) 2.4942\n",
            "0m 0s (- 0m 1s) (16 32%) 8.9211\n",
            "0m 0s (- 0m 0s) (17 34%) 1.7887\n",
            "0m 0s (- 0m 0s) (18 36%) 5.8834\n",
            "0m 0s (- 0m 0s) (19 38%) 2.4546\n",
            "0m 0s (- 0m 0s) (20 40%) 1.3364\n",
            "0m 0s (- 0m 0s) (21 42%) 2.4500\n",
            "0m 0s (- 0m 0s) (22 44%) 2.4308\n",
            "0m 0s (- 0m 0s) (23 46%) 1.4982\n",
            "0m 0s (- 0m 0s) (24 48%) 1.9705\n",
            "0m 0s (- 0m 0s) (25 50%) 2.4519\n",
            "0m 0s (- 0m 0s) (26 52%) 3.6765\n",
            "0m 0s (- 0m 0s) (27 54%) 1.4090\n",
            "0m 0s (- 0m 0s) (28 56%) 1.7707\n",
            "0m 0s (- 0m 0s) (29 57%) 2.6472\n",
            "0m 0s (- 0m 0s) (30 60%) 2.0410\n",
            "0m 0s (- 0m 0s) (31 62%) 6.6951\n",
            "0m 0s (- 0m 0s) (32 64%) 1.7889\n",
            "0m 0s (- 0m 0s) (33 66%) 2.2440\n",
            "0m 0s (- 0m 0s) (34 68%) 8.8081\n",
            "0m 0s (- 0m 0s) (35 70%) 2.9964\n",
            "0m 0s (- 0m 0s) (36 72%) 2.0755\n",
            "0m 0s (- 0m 0s) (37 74%) 1.7897\n",
            "0m 1s (- 0m 0s) (38 76%) 1.4679\n",
            "0m 1s (- 0m 0s) (39 78%) 2.4038\n",
            "0m 1s (- 0m 0s) (40 80%) 2.9621\n",
            "0m 1s (- 0m 0s) (41 82%) 5.1141\n",
            "0m 1s (- 0m 0s) (42 84%) 8.8897\n",
            "0m 1s (- 0m 0s) (43 86%) 2.1977\n",
            "0m 1s (- 0m 0s) (44 88%) 2.5843\n",
            "0m 1s (- 0m 0s) (45 90%) 5.3592\n",
            "0m 1s (- 0m 0s) (46 92%) 4.4611\n",
            "0m 1s (- 0m 0s) (47 94%) 8.7861\n",
            "0m 1s (- 0m 0s) (48 96%) 8.7672\n",
            "0m 1s (- 0m 0s) (49 98%) 2.5525\n",
            "0m 1s (- 0m 0s) (50 100%) 2.9293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm8ns1zoJB-W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS9We9ZU8bre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder.initcellstate()\n",
        "\n",
        "        # encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden,encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden,encoder_cell)\n",
        "            # encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = encoder_cell\n",
        "        decoded_words = []\n",
        "        # decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden,decoder_cell = decoder(\n",
        "                decoder_input, decoder_hidden,decoder_cell)\n",
        "            # decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1dYNPb8eHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vca5iI5L0BRw",
        "colab_type": "code",
        "outputId": "fe526c23-8eec-41bf-933b-f7e2e08a6c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(input_lang.n_words)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DXfF12H8rNL",
        "colab_type": "code",
        "outputId": "ff77e3bb-082a-419a-f123-da479a514581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> this is the christmas message from nico .\n",
            "=  ay la tin nhan giang sinh tu nico .\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> b it apos s interesting .\n",
            "= b ieu o rat hay\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> you apos re going to sit on these hard chairs for an hour and a half .\n",
            "= ban se phai ngoi tren may chiec ghe cung nay trong mot gio ruoi .\n",
            "< toi toi toi toi toi toi <EOS>\n",
            "\n",
            "> well i put on my backpack again .\n",
            "= va toi lai xach ba lo\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> now the really clever bit is what they did with the cardboard waste .\n",
            "=  ieu ho lam voi cac tam bia cung bo i that su rat thong minh .\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> again you don apos t have to click one of the results .\n",
            "= ban cung khong can phai an vao trong cac ket qua .\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> so many many useful things come out of this .\n",
            "= suy ra rat nhieu thu huu ich a ra oi tu kha nang uoc lam theo y muon .\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> how much money does he spend on beer in a year ?\n",
            "= anh ta uong bia het bao nhieu tien mot nam ?\n",
            "< toi toi toi <EOS>\n",
            "\n",
            "> a kind of induction a kind of spread from person to person .\n",
            "= mot kieu cam ung mot loai lan truyen tu nguoi nay sang nguoi khac .\n",
            "< toi toi toi toi <EOS>\n",
            "\n",
            "> do i go from a percent chance to a percent chance ?\n",
            "= co phai toi i tu phan tram rui ro len phan tram rui ro khong ?\n",
            "< toi toi toi <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WOs79j0BY_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icCvahalHOMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWda4e48FLT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "# import matplotlib.ticker as ticker\n",
        "# import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKVX8GNBzeR",
        "colab_type": "code",
        "outputId": "486b4729-a653-44e2-ac06-4fd4baec68ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "output_words = evaluate(\n",
        "    encoder1, decoder1, \"so the sweet spot is between and .\")\n",
        "# plt.matshow(attentions.numpy())\n",
        "print(output_words)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['toi', 'toi', 'toi', '<EOS>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_VdBg6EzfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHpaNLG_FG2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_GdRlFcc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(attentions.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA24gW3JFz35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.matshow(attentions.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-6wIjIdpVNu",
        "colab_type": "text"
      },
      "source": [
        "1. BiLSTM\n",
        "2. GloVE embedding\n",
        "3. presentation\n",
        "4. BLUE Score and how error is calculated here\n",
        "5. Figure out how attention figures are made.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YOZ1jJGndf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}